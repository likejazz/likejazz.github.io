---
layout: post
title: 비전공자도 이해할 수 있는 AI 지식 용어집
tags: ["Books"]
last_modified_at: 2024/10/24 17:51:14
---

<div class="message">
『비전공자도 이해할 수 있는 AI 지식』 책에 나오는 용어를 정리합니다.
</div>

<small>
*2022년 3월 3일 초안 작성*  
</small>

<!-- TOC -->

- [1장 인공지능](#1장-인공지능)
- [2장 알파고](#2장-알파고)
- [3장 자율주행](#3장-자율주행)
- [4장 검색엔진](#4장-검색엔진)
- [5장 스마트 스피커](#5장-스마트-스피커)
- [6장 기계번역](#6장-기계번역)
- [7장 챗봇](#7장-챗봇)
- [8장 내비게이션](#8장-내비게이션)
- [9장 추천](#9장-추천)
- [판매처](#판매처)

<!-- /TOC -->

# 1장 인공지능
<img src="https://lh3.googleusercontent.com/pw/AM-JKLVKnpnSGpJ8z92Bn0gjsgweVXG-0IytI890syt0CpbiLDk6FVxg-G70aQw6P-y--i9QMF6S3rdDmOW3VsrzkqPw6QJkTaPKD9O653gsIVlNjAa517ah6U_hdt6bjNr0reNvU-OLsQrG9Cc0byO0ucfDUg=w670-h634-no?authuser=0" width="50%">

- **메케니컬 터크<sup>Mechanical Turk</sup>**  
18세기 후반에 등장한 체스를 두는 자동기계입니다. 실제로는 기계 내부에 사람이 들어앉아 조작했던 정교한 사기였습니다.
- **모라벡의 역설<sup>Moravec's Paradox</sup>**  
다섯 살배기 아이한테는 쉬운 일이 기계한테는 어렵고, 반대로 기계한테는 쉬운 일이 인간에게는 어려운 역설적인 상황을 말합니다. 인간에게 어려운 복잡한 수학 계산은 기계가 잘하지만, 체스 말을 원하는 위치에 옮기는 등 다섯 살배기도 할 수 있는 일은 기계가 하기 어렵습니다.
- **인공 신경망<sup>Artificial Neural Network</sup>**  
인간의 두뇌구조를 본뜬 머신러닝 모델입니다.
- **퍼셉트론<sup>Perceptron</sup>**  
1958년에 등장한 초기 인공 신경망 알고리즘입니다. 많은 기대와 주목을 한 몸에 받았으나 풀 수 없는 문제가 많았고, 복잡한 신경망을 제대로 학습할 수 있는 방법도 알지 못해 한동안 사람들의 기억 속에서 잊힙니다.
- **에이다 러브레이스<sup>Ada Lovelace</sup>**  
컴퓨터가 등장하기도 전에 프로그래밍 언어의 개념을 정립한 세계 최초의 프로그래머로, 인공지능의 출현 가능성을 추론해냈습니다.
- **if-then 규칙**  
'만약 O라면, O이다'라는 형태의 조건문을 이용해 규칙을 정하고 결론을 도출하는 방식입니다. 대부분의 규칙은 사람이 일일이 입력합니다. 초창기 인공지능을 구현하는 데 널리 활용되었습니다.
- **머신러닝<sup>Machine Learning</sup>**  
기존의 규칙 기반과 달리 더 이상 'if-then 규칙'을 입력하지 않고 데이터에서 스스로 규칙을 찾아내는 컴퓨터 알고리즘 연구를 말합니다.
- **아마존 메케니컬 터크<sup>Amazon Mechanical Turk</sup>**  
인공지능을 위한 기초 데이터를 사람이 만들어내는 아마존의 플랫폼 서비스입니다. 사람이 직접 만들어낸다는 점에서 원래 메케니컬 터크의 작동 원리와 일맥상통합니다.
- **제프리 힌튼<sup>Geoffrey Hinton</sup>**  
토론토대학교의 교수로 평생을 인공 신경망을 연구하며 잊힌 알고리즘이었던 인공 신경망을 딥러닝으로 부활시킨 인물입니다. 지금의 딥러닝을 있게 한 일등 공신을 꼽으라면 단연 힌튼 교수입니다.
- **딥러닝<sup>Deep Learning</sup>**  
오랫동안 잊힌 알고리즘이었던 인공 신경망을, 다양한 연구를 통해 제대로 된 학습 방법을 찾아내고 한계를 극복하면서 2000년대 들어 부르기 시작한 인공 신경망의 새로운 이름입니다.
- **대중의 지혜<sup>The Wisdom of Crowds</sup>**  
다양한 집단의 데이터가 많이 모이면 소수 전문가의 의견보다 더 정답에 근접한 결과를 얻어낼 수 있다는 원리로, 〈뉴요커〉의 논설위원 제임스 서로위키가 쓴 《대중의 지혜》라는 동명의 책 제목으로 인해 널리 알려졌습니다.
- **무어의 법칙<sup>Moore's Law</sup>**  
1965년 인텔의 공동창업자 고든 무어가 내놓은 법칙으로, "반도체 칩의 트랜지스터 집적도는 2년마다 2배씩 증가한다"고 주장한 법칙입니다. 40년 넘게 비슷하게 맞아떨어지며 반도체 발전을 주도해왔습니다.
- **GPU<sup>Graphics Processing Unit</sup>**  
원래는 게임 그래픽 처리를 위한 전용 칩셋이었으나 이후 병렬연산에 최적화되어 있다는 점을 이용해 다양한 과학 계산에 활용됩니다. 특히 딥러닝과 블록체인에 필요한 가장 중요한 핵심 하드웨어로 자리 잡습니다.
- **CUDA<sup>Compute Unified Device Architecture</sup>**  
마이크로소프트가 게임 개발을 위해 DirectX라는 API를 제공하는 것처럼 GPU로 병렬연산을 할 수 있도록 엔비디아가 직접 제공한 기술입니다. 이 기술로 인해 GPU 시장은 사실상 엔비디아의 독점이라고 할 수 있습니다.
- **오픈소스<sup>Open Source</sup>**  
사전적 의미로는 수정 및 재배포가 가능한 무료로 제공되는 소스코드를 뜻합니다. 그러나 단순한 공개를 넘어 개방형 협업에 참여를 장려하며, 이를 통해 영향력을 더욱 공고히 할 수 있는 혁신적인 모델입니다. 대표적인 성공 사례로 리눅스가 있으며, 최근에는 수많은 상업용 소프트웨어도 오픈소스에 참여하며 혁신을 가속화하고 있습니다.
- **텐서플로<sup>TensorFlow</sup>**  
구글 내부에서 사용하던 딥러닝 라이브러리를 2015년 가을에 오픈소스로 공개한 프로그램으로, 현재 딥러닝 프로그램 점유율 1위를 차지하고 있습니다.
- **파이토치<sup>PyTorch</sup>**  
페이스북에서 오픈소스로 공개한 딥러닝 프로그램으로, 텐서플로에 이어 두 번째로 점유율이 높습니다. 특히 간단하고 직관적인 방식으로 복잡한 모델도 이해하기가 쉬워서 연구자들이 논문을 쓸 때 가장 많이 활용하는 프로그램입니다.

# 2장 알파고
<img src="https://lh3.googleusercontent.com/pw/AM-JKLXAC7BEK1Ia-Mv0UBar4ClC9IzlcAC_pHTGQp6bln8c_tqNEQ6tMB4LeeaWgwVPGuQ_rhy9RuGIn_WFU5COVoIz3v2JxVJmkRLgN0-3eGv_rDV_PsSyApFJSWw6tAXDJhXYZOOOwvEH2kedKN-ADK47ZA=w915-h712-no?authuser=0" width="40%">

- **가리 카스파로프<sup>Garry Kasparov</sup>**  
1984년부터 2005년 은퇴할 때까지 22년간 세계 랭킹 1위를 유지한 전설적인 체스 세계 챔피언으로, 1997년에 IBM의 체스 컴퓨터 딥 블루에 패배합니다. 2017년에는 딥 블루와의 회고록 《딥 씽킹》을 출간했습니다.
- **딥 블루<sup>Deep Blue</sup>**  
IBM이 만든 체스에 특화된 컴퓨터입니다. 1997년 체스 세계 챔피언 가리 카스파로프를 꺾으며 세계 챔피언이 됩니다. 480개의 체스 전용 칩을 내장하고, 초당 2억 번의 이동을 계산할 수 있었습니다. 엄청난 연산 능력을 바탕으로 가능한 모든 경우의 수를 탐색하고 다음 수를 결정하는 형태로 작동했습니다.
- **게임 트리<sup>Game Tree</sup>**  
체스에서 현재 수는 이전 수에 영향을 받고, 또 다음 수에 영향을 줍니다. 계속해서 영향을 주며 길게 뻗어나가는 모습을 마치 나무를 뒤집은 모양으로 표현한 것을 말합니다.
- **가지치기<sup>Pruning</sup>**  
모든 경로를 매번 탐색하는 것은 비효율적이기 때문에 막다른 길인 경우 나뭇가지 자르듯 쳐내고 더 이상 탐색하지 않는 알고리즘을 말합니다.
- **몬테카를로 방법<sup>Monte Carlo Method</sup>**  
카지노로 유명한 도박의 도시 몬테카를로를 빗댄 이름으로, 도박처럼 확률적인 방법으로 결과를 유추해내는 알고리즘입니다.
- **몬테카를로 트리 탐색<sup>Monte Carlo Tree Search</sup>**  
게임 트리 탐색에 몬테카를로 방법을 접목한 것으로, 2006년부터 사용하면서 바둑 인공지능의 실력을 높이는 데 결정적인 역할을 합니다. 선택-확장-시뮬레이션-업데이트 과정을 통해 다음 수를 결정합니다.
- **정책망<sup>Policy Network</sup>**  
알파고에 사용된 두 종류의 인공 신경망 중 하나로, 어디에 돌을 내려놓을지를 예측하는 망입니다. 알파고는 서로 다른 3가지 형태의 정책망을 만들어 사용합니다.
- **가치망<sup>Value Network</sup>**  
알파고에 사용된 두 종류의 인공 신경망 중 하나로, 현재 국면에서 승리할 가능성이 높은지, 패배할 가능성이 높은 지를 확률로 표현한 망입니다. 알파고는 강화 학습의 결과로 가치망을 구축합니다.
- **강화 학습<sup>Reinforcement Learning</sup>**  
최적의 행동을 취할 때마다 보상을 통해 스스로 보상을 최대화하는 방향으로 학습을 진행하는 머신러닝의 한 영역으로, 주로 게임 인공지능을 만드는데 널리 사용됩니다. 여러 차례 시행착오를 통해 최적의 의사결정을 내리도록 학습하는 방식으로, 알파고의 성능을 높인 핵심이기도 합니다.
- **알파고 제로<sup>AlphaGo Zero</sup>**  
인간 기보가 필요 없이 완전히 스스로 대국을 통해 실력을 쌓아나가는 알파고의 최신 버전으로, 이세돌을 이긴 알파고에 100:0으로 승리하였습니다. 이후 바둑뿐만 아니라 체스, 장기 같은 보드게임도 스스로 학습하는 알파제로<sup>AlphaZero</sup>가 등장합니다.
- **엘로 평점<sup>Elo Rating</sup>**  
체스 시절에 만들어진 점수 체계로 바둑에서도 동일하게 사용합니다. 이기면 증가하고 패하면 감소하는 방식인데, 점수가 균일한 폭으로 증감하는 게 아니라 나보다 점수가 높은 상대를 이길 경우에는 점수가 큰 폭으로 증가하고, 나보다 점수가 낮은 상대를 이길 경우에는 점수가 작은 폭으로 증가합니다. 어려운 미션에 더 큰 보상을 주는 매우 합리적인 점수 산정 방식입니다.

# 3장 자율주행
<img src="https://lh3.googleusercontent.com/pw/AM-JKLVsIs8y8NkZV6ODB5ZfvxEG2UtXJWV5ik0uJaPy5Mt0fAUW6DOWDjLkRGK4Y401hQCLF6DpgsZEXZA7fa9adPn3Axp08PUNAZ-iZr76omwmbrqnIbU6un5a_5ZtZAJDVaM6xa5Ai2u_pv8yPfoM_Ne8Bw=w670-h353-no?authuser=0" width="50%">

- **다르파<sup>DARPA, Defense Advanced Research Projects Agency</sup>**  
미 국방부 산하의 연구조직입니다. 혁신적인 연구를 후원해 '미친 과학국'이라는 별명이 붙었죠. 1957년에 소련이 세계 최초로 인공위성 스푸트니크 1호를 발사하자, 깜짝 놀란 미국이 이에 대응하여 창설한 군사적 목적의 연구기관입니다. 인터넷, 음성인식, 군사용 드론, 자율주행 등이 모두 다르파의 후원으로 탄생했습니다.
- **세바스찬 스런<sup>Sebastian Thrun</sup>**  
첫 번째 대회의 악몽을 딛고 두 번째 자율주행차대회에서 우승을 차지한 스탠퍼드대학교의 책임자로, 이후 구글에 합류하여 스트리트 뷰를 만들고 2009년에는 구글에서 자율주행 프로젝트를 시작합니다.
- **스탠리<sup>Stanley</sup>**  
두 번째 자율주행차대회에서 최초로 완주하고 우승을 차지한 스탠퍼드대학교의 자율주행차 이름입니다.
- **베이즈 정리<sup>Bayes' Theorem</sup>**  
불확실한 의사결정 문제를 수학적으로 다룰 때 이용되는 정리로, 확률을 믿음으로 바라보는 경험적인 추론을 사용합니다. 베이즈를 따르는 이들을 베이즈주의자<sup>Bayesian</sup>라 일컫습니다.
- **빈도주의자<sup>Frequentist</sup>**  
고전 통계학을 따르며 확률을 빈도<sup>Frequency</sup>로 바라보는 전통적인 방식을 따르는 이들을 말합니다. 확률을 믿음으로 바라보는 베이즈주의자와 오랜 기간 갈등을 빚어왔습니다.
- **레이더<sup>Radar</sup>**  
전자파를 쏘아올려 물체에 반사된 반사파를 측정해 물체의 거리, 속도, 방향 등을 판단하는 장비입니다. 2차 세계대전 전후에 영국에서 개발되어 전쟁에서 독일의 움직임을 사전에 포착하는 등의 활약을 합니다.
- **라이다<sup>LiDAR</sup>**  
빛<sup>Light</sup>과 레이더<sup>Radar</sup>의 합성어로, 레이더가 전자파를 발사해 반사파를 측정한다면, 라이다는 레이저 빛을 발사해 반사되어 돌아오는 것을 측정합니다. 레이더에 비해 물체의 거리와 방향을 훨씬 더 정교하고 입체적으로 파악합니다.
- **얀 르쿤<sup>Yann LeCun</sup>**  
페이스북의 인공지능 연구소장으로, 초창기 인공 신경망에 컨볼루션이라는 기법을 적용하여 손으로 쓴 우편번호를 인식하는 이미지 인식을 성공적으로 구현해 냈습니다.
- **컨볼루션 신경망<sup>CNN, Convolutional Neural Network</sup>**  
동물의 시각피질 작동 원리에 영향을 받은 것으로, 동물의 눈으로 사물을 바라보는 것과 비슷하게 필터를 이용해 이미지 정보를 처리하는 인공 신경망입니다. 컨볼루션 작업을 거치면 이미지에 대한 다양한 특징이 남게 되고 이런 다양한 특징을 모아서 학습하면 컨볼루션 방식의 딥러닝이 완성됩니다.
- **모방학습<sup>Imitation Learning</sup>**  
행동을 모방하는 학습 방식입니다. 대표적으로 테슬라가 인간의 주행 방식을 모방해 자율주행을 학습하는 데 활용합니다.
- **도덕 기계<sup>Moral Machine</sup>**  
MIT에서 광차 문제를 자율주행차의 문제로 변형하여 도덕적 딜레마를 온라인에서 실험한 플랫폼입니다. 
- **광차 문제<sup>Trolley Problem</sup>**  
유명한 윤리학의 사고 실험(머릿속에서 생각으로 진행하는 실험)으로, 어쩔 수 없는 상황에서 더 많은 사람을 살리기 위해 다른 누군가를 희생시킬 수 있는가와 같은 문제를 일컫습니다. 1960년대부터 철학과 학생들이 수십 년간 논쟁을 벌여온 문제이며, 비슷한 문제를 자율주행차의 경우에도 고민해볼 수 있습니다.

# 4장 검색엔진
- **쿼리<sup>Query</sup>**  
원하는 정보를 찾기 위해 검색엔진에 사용자가 직접 질의하는 내용을 말합니다. 쉽게 얘기해서 "검색어를 입력하세요"라고 할 때 '검색어'가 바로 쿼리입니다.
- **CPC<sup>Cost Per Click</sup> 방식**  
인터넷 광고의 과금 방식 중 하나로, 광고를 클릭할 때마다 비용을 책정하는 종량제 방식입니다.
- **색인<sup>Index</sup>**  
검색을 빠르게 수행할 수 있도록 문서를 수집하여 검색에 적합하도록 보관하고 있는 것을 말합니다.
- **구글 파일 시스템<sup>GFS, Google File System</sup>**  
구글에서 개발한 효율적인 분산 파일 시스템입니다. 구글은 이 시스템을 이용해 엄청난 양의 색인을 저장했으며, 이후 기술에 대한 논문을 공개합니다. 논문을 기반으로 오픈소스로 시작된 프로젝트가 하둡<sup>Hadoop</sup>입니다. 현재 하둡은 모든 대기업이 활용하고 있을 정도로 인기가 높으며, 빅 데이터가 곧 하둡이라 해도 과언이 아닐 정도로 빅 데이터를 대표하는 유명한 플랫폼입니다. 그 시작은 구글 파일 시스템의 논문입니다.
- **크롤러<sup>Crawler</sup>**  
웹 사이트에서 정보를 수집하기 위해 사이트 구석구석을 돌아다니는 로봇을 말하며 웹 페이지를 갈고리처럼 긁어온다고 하여 크롤러<sup>Crawler</sup>라고 부릅니다. 웹은 링크로 서로서로 연결된 거미줄<sup>Web</sup>과 유사한 모습을 띠고 있기 때문에 웹 사이트에서 정보를 수집하는 로봇을 스파이더<sup>Spider</sup>(거미)라고도 부릅니다. 최근에는 크롤러라는 명칭을 좀 더 일반적으로 사용합니다.
- **에르되시 수<sup>Erdős Number</sup>**  
전 세계를 돌아다니며 평생을 수학 연구에만 몰두해온 에르되시 팔은 대부분의 논문을 다른 학자들과 함께 공동으로 집필했습니다. 에르되시 수는 그와 몇 단계에 걸쳐 네트워크로 연결되어 있는지를 나타내는 수입니다. 수학 저널에 논문을 한 편이라도 기고한 수학자의 경우, 거의 대부분이 8 이하에 해당한다고 알려져 있습니다.
- **페이지 랭크<sup>Page Rank</sup>**  
유명한 사이트가 많이 가리킬수록 점수가 올라간다는 알고리즘으로, 초기 구글 검색의 핵심 알고리즘입니다.
웹 문서<sup>Page</sup>를 랭크했다는 의미와 동시에 구글 창업자 중 한 명인 래리 페이지의 이름을 따서 페이지 랭크로 부릅니다.
- **댐핑 팩터<sup>Damping Factor</sup>**  
페이지 랭크 알고리즘에서 사용자들이 싫증을 낼 확률을 반영한 값을 말합니다. 링크를 따라가 웹 문서를 읽다가 어느 순간 흥미를 잃어 해당 문서를 벗어날 확률이 15%면, 댐핑 팩터는 이 값을 반영하여 0.85가 됩니다.
- **근접도<sup>Proximity</sup>**  
쿼리와 매칭 되는 단어가 얼마나 서로 가까이에 있는지 판단하는 점수로, 단어와 단어 사이의 간격이 좁을수록 더 유사한 문서라고 판단하고 더 높은 점수를 줍니다.
- **TF-IDF**  
추천 시스템의 83%가 사용하는, 검색엔진과 추천 시스템을 대표하는 유사도 계산 알고리즘입니다. 단어의 출현 빈도(TF)와 문서 출현 빈도의 역수(IDF)를 곱한 값입니다.
- **BM25**  
TF-IDF를 기반으로 하는 유사도 계산 알고리즘 중 가장 성능이 좋다고 알려진 방식으로 구글, 네이버, 다음 등 사실상 국내외 모든 검색엔진이 채택하고 있는 유사도 계산 알고리즘입니다.
- **A/B 테스트**  
무작위 대조 시험을 온라인에서 구현한 것으로, 서로 다른 결과를 보여주고 어느 방식이 더 효과적인지 성과를 측정하는 방식입니다. 랭킹 개선의 효과를 효율적으로 측정하는 방식이기도 합니다.
- **검색엔진 최적화<sup>SEO, Search Engine Optimization</sup>**  
검색엔진에 사이트가 잘 노출되도록 최적화하는 작업을 말합니다. 단순히 노출 최적화를 넘어 랭킹을 높이기 위해 여러 시도를 하기도 합니다. 반면 검색엔진 업체는 쉽게 랭킹을 올릴 수 없도록 계속해서 방어 로직을 개선합니다.
- **MUM<sup>Multitask Unified Model</sup>**  
2021년 상반기에 발표한 구글의 새로운 검색 알고리즘입니다. 복잡한 질문에 답하기 위해 딥러닝과 결합한 새로운 기술로, 복잡한 쿼리를 이해할 뿐만 아니라 75개 언어를 모두 통합하여 학습한 모델을 구축했고 여기에 더해 비디오나 이미지 같은 정보도 함께 찾아서 결과를 보여줍니다.

# 5장 스마트 스피커
- **시리<sup>Siri</sup>**  
시리는 스탠퍼드대학교에서 시작된 민간 연구소 SRI 인터내셔널의 연구 프로젝트였습니다. 가능성을 본 일부 연구원이 독립해 창업을 했고, 시리는 당시 회사의 이름이자 제품의 이름이었습니다. 2010년에는 애플이 인수하여 이듬해 아이폰에 탑재해 동일한 이름으로 세상에 내놓습니다. 음성인식 비서라는 카테고리를 사실상 처음으로 개척한 서비스입니다.
- **빅스비<sup>Bixby</sup>**  
삼성전자의 음성 비서입니다. 시리를 만든 대그 키틀러스와 애덤 체이어 등이 애플을 퇴사하면서 비브랩스라는 인공지능 개인 비서를 만드는 회사를 창업했고, 이 회사를 삼성전자가 인수하면서 탄생합니다.
- **알렉사<sup>Alexa</sup>**  
아마존에서 개발한 인공지능 플랫폼으로, 인류의 지식과 배움의 중심지였던 고대 이집트 도서관 알렉산드리아에 대한 오마주입니다. 아마존의 스마트 스피커 에코에서 처음 사용되었습니다.
- **웨이크업<sup>Wake-Up</sup>**  
호출어를 부르는 등의 작업을 통해 스마트 스피커를 깨우는 과정입니다.
- **은닉 마르코프 모델<sup>Hidden Markov Model</sup>**  
은닉된<sup>Hidden</sup> 상태와 관찰 가능한 결과로 구성된 통계적 모델로, 이를 이용해 초기 음성 인식에서 좋은 성과를 냅니다.
- **순환 신경망<sup>RNN, Recurrent Neural Network</sup>**  
시간의 흐름에 따라 순서대로 구성되는 시계열 형식을 학습할 수 있는 인공 신경망 구조입니다.
- **음향 모델<sup>Acoustic Model</sup>**  
음성인식 과정에서 음성의 파형으로 단어를 인식하는 모델입니다.
- **언어 모델<sup>Language Model</sup>**  
단어가 등장할 확률을 계산하는 모델로 음성인식에서 잘못 인식된 단어를 보정하는 역할을 합니다. 음성인식 시스템은 음향 모델로 인식한 결과를 언어 모델로 보정하는 과정을 거칩니다. 이외에도 언어 모델은 챗봇 등 자연어 처리의 다양한 분야에서 널리 사용합니다.
- **자연어 이해<sup>NLU, Natural Language Understanding</sup>**  
말이나 글의 의미가 무엇인지 알 수 있도록 언어를 구조화하는 과정입니다.
- **슬롯 필링<sup>Slot Filling</sup>**  
필요한 정보를 수집하여 누락된 정보를 채워주는 과정입니다.
- **멀티 턴<sup>Multi-Turn</sup>**  
슬롯 필링을 위해 여러 번 대화를 반복하는 과정입니다.
- **다이얼로그 매니저<sup>Dialog Manager</sup>**  
대화 시스템의 상태를 관리하는 역할을 하며, 이전 대화 내용을 기억하거나 자연어 이해에서 처리해준 내용을 받아서 실행 명령을 내리는 역할을 담당합니다.
- **스킬<sup>Skill</sup>**  
스마트 스피커가 할 수 있는 기능으로, 스마트폰의 앱과 유사합니다. 스피커 제조사마다 조금씩 다르게 부르지만 아마존이나 카카오, 네이버는 모두 이러한 서비스 기능을 스킬이라고 부릅니다.
- **문제해결용 대화시스템<sup>Task-Oriented Dialogue System</sup>**  
특정 주제로 제한하여 목적을 이루기 위해 대화를 이어가는 시스템입니다. 대표적으로 고객의 문제를 해결해주는 용도인 고객센터 챗봇이 있습니다.
- **USS<sup>Unit Selection Synthesis</sup>**  
미리 녹음된 음성을 기준에 따라 잘게 쪼개어 음편<sup>Unit</sup>을 만들고 가장 적합한 음편을 선택<sup>Selection</sup>하여 음성을 합성<sup>Synthesis</sup>하는 방식으로, 연결 합성이라고도 합니다. 성우가 미리 녹음한 음성을 이어 붙이므로 매우 자연스럽다는 장점이 있습니다. 지하철 안내 방송, 내비게이션, 스마트 스피커가 주로 사용하는 방식입니다.
- **타코트론 2<sup>Tacotron 2</sup>**  
구글이 제안한 음성 합성 모델로 이후 음성 연구 분야에 매우 큰 영향을 끼칩니다. 특히 엔비디아에서 구현한 모델은 자체 개발한 딥러닝 보코더를 탑재하여 매우 깨끗한 음질을 들려줍니다.
- **멜 스펙트로그램<sup>Mel Spectrogram</sup>**  
소리나 파동을 시각화하여 파악할 수 있도록 표현한 것입니다. 음파와 비슷하게 생겼지만 색상의 차이, 농도를 포함해 보다 풍부한 정보를 표현할 수 있으며, 이를 인간이 인지할 수 있는 주파수 대역으로 변환해 낮은 해상도로 압축합니다.
- **보코더<sup>Vocoder</sup>**  
멜 스펙트로그램을 실제 음성으로 바꾸는 기술입니다. 최근에는 멜 스펙트로그램 추출 없이 텍스트에서 음성을 바로 생성하는 진정한 엔드투엔드 방식의 모델을 연구하고 있습니다.

# 6장 기계번역
<img src="https://lh3.googleusercontent.com/pw/AM-JKLWygwZT9xyLr6y83KC3_FeH7pdpUZcFgredub7wzApPaZq27gj7QsM_TCkXpMCdMsXEeStVTKH7CubjkbfMBJE8dqNOn6CprFiGrIYZyK5G3wQQVMkARQ9Pcdk8cYxPsEcfQTSd7a8TV2LM8r9kc9-6gQ=w670-h467-no?authuser=0" width="50%">

- **기계번역<sup>Machine Translation</sup>**  
컴퓨터를 사용해 인간이 사용하는 언어를 다른 언어로 번역해내는 것을 말합니다.
- **시스트란<sup>SYSTRAN</sup>**  
초창기 기계번역을 연구한 대표적인 회사로, 1968년에 설립하여 50년의 역사를 자랑합니다. 규칙 기반 기계번역으로 당시에는 독보적인 성능을 자랑했습니다.
- **규칙 기반 기계번역<sup>Rule-Based Machine Translation</sup>**  
언어학자들이 일일이 규칙을 정의하고 그 규칙에 따라 번역을 제공하는 방식입니다.
- **예시 기반 기계번역<sup>Example-Based Machine Translation</sup>**  
규칙을 통해 언어를 이해하기보다, 경험을 통해 모방하는 형태로 접근한 번역 방식입니다. 기본적인 문장의 의미를 파악한 다음 비슷한 문장의 의미를 비교해 전체 의미를 유추하는 방식입니다. 마치 영어를 공부할 때 먼저 숙어를 암기하고 숙어에 단어를 갈아 끼우며 전체 문장을 번역하는 과정과 유사합니다.
- **통계 기반 기계번역<sup>Statistical Machine Translation</sup>**  
문장을 단어 또는 구문 단위로 분할한 다음 이를 번역하고 다시 문장으로 합치는 과정에 확률적인 방법을 접목한 방식을 말합니다. 수많은 문장을 분석해 확률을 스스로 계산합니다.
- **조경현**  
신경망 기계번역을 도입한 인공지능 분야의 과학자로, 현재 뉴욕대 교수이자, 페이스북에 근무합니다. 한국인으로서는 인공지능 분야에서 독보적인 성과를 냈습니다.
- **신경망 기반 기계번역<sup>Neural Machine Translation</sup>**  
인공 신경망을 이용해 문장 전체를 마치 하나의 단어처럼 통째로 번역하는 방식입니다. 훨씬 더 자연스러운 번역을 가능하게 했습니다.
- **인코더<sup>Encoder</sup>**  
기계번역에서 문장의 의미를 압축하는 과정입니다.
- **디코더<sup>Decoder</sup>**  
기계번역에서 압축을 풀어 번역문을 만드는 과정입니다.
- **어텐션<sup>Attention</sup>**  
문장을 번역할 때 보다 중요한 단어는 별도로 강조하겠다는 원리로 출발했으며, 문장 전체를 한번만 압축했던 초기 신경망 기반 기계번역에 비해 마치 형광펜으로 매 번 중요한 부분을 표시해서 번역하는 것과 유사합니다. 실제로 기계번역의 성능을 크게 높였습니다.
- **트랜스포머<sup>Transformer</sup>**  
어텐션이 좋은 성과를 내면서 아예 어텐션만으로 인공 신경망을 구성한 모델입니다. 이후 각종 분야를 휩쓸면서 모든 자연어 처리 분야의 성능을 월등히 높입니다.

# 7장 챗봇
- **이루다**  
국내 스타트업이 개발한 챗봇으로, '이루다'라는 이름은 어떤 주제로든 자유롭게 대화할 수 있는 인공지능을 이루었다는 의미입니다. 출시 직후 75만 명이 이용하며 큰 화제를 불러일으켰으나 개인정보 침해 논란 등으로 겨우 2주 만에 서비스를 중단합니다.
- **자유 주제 대화 시스템<sup>Open-Domain Dialogue System</sup>**  
주제에 제약을 받지 않고 어떤 주제든 자유롭게 대화를 이어나갈 수 있는 대화 시스템입니다.
- **일라이자<sup>ELIZA</sup>**  
1966년, MIT의 컴퓨터과학자 요제프 바이첸바움이 만든 세계 최초의 챗봇입니다. 아직 이른 시기였고, 기술의 한계로 인해 단순한 규칙으로 구현되었으나 그럼에도 불구하고 사람처럼 대화하는 챗봇은 큰 파장을 불러일으킵니다.
- **컴파일러<sup>Compiler</sup>**  
한 언어를 다른 언어로 바꿔주는 과정을 컴파일이라고 하며, 컴파일러는 컴파일을 수행하는 도구입니다. 컴퓨터에 비유하면 인간이 이해하는 고수준 언어(C++, 자바, 파이썬)를 기계가 이해하는 저수준 언어(기계어)로 바꾸는 과정을 수행하는 도구입니다.
- **그레이스 호퍼<sup>Grace Hopper</sup>**  
컴파일러의 개념을 최초로 고안했으며, 코볼이라는 프로그래밍 언어가 탄생하는 데 핵심적인 역할을 하여 코볼의 어머니로 불리기도 합니다.
- **코볼<sup>COBOL</sup>**  
컴퓨터 프로그래밍 언어로, 문법이 영어와 매우 흡사합니다. 마치 사람에게 말로 지시하듯, 회계·매출·급여 등 비즈니스와 관련한 업무를 영어로 기술하면 컴파일러가 컴퓨터가 이해할 수 있는 언어로 바꿔줍니다. 코볼로 인해 과학 계산에 주로 쓰이던 컴퓨터를 비즈니스에 본격적으로 활용합니다.
- **좌표<sup>Coordinates</sup>**  
서로 다른 분야로 여겨지던 기하학과 대수학의 개념을 하나로 합쳐낸 혁신적인 발상으로 '나는 생각한다. 고로 존재한다'라는 명언이 실려 있던 《방법서설》을 통해 데카르트가 처음 고안했습니다. 천장에 붙어 있는 파리의 위치를 표현하는 방법을 고민하다가 좌표의 개념을 고안했으며, 기하학과 대수학의 관계를 밝혀내자 17세기 수학자들은 엄청난 충격을 받습니다.
- **클로드 섀넌<sup>Claude Shannon</sup>**  
MIT의 대학원생 시절 이진법을 이용해 모든 정보를 전달할 수 있는 방법을 고안합니다. 정보 이론이라는 새로운 학문을 탄생시켰고 컴퓨터는 0과 1, 단 2개의 숫자로 모든 계산을 해낼 수 있게 되었습니다. 이 단위를 비트라 부르며, 마침내 세상은 정보통신의 시대로 접어들게 됩니다.
- **워드투벡<sup>Word2Vec</sup>**  
2013년 구글은 단어의 의미를 벡터로 표현하는 매우 획기적인 방법을 발표합니다. 이름부터 단어<sup>Word</sup>를 벡터<sup>Vector</sup>로 바꾼다는 매우 직관적인 의미이며, 놀랍도록 정교하게 단어의 의미를 표현해내어 많은 이가 깜짝 놀랐습니다.
- **원-핫 벡터<sup>One-Hot Vector</sup>**  
단어를 가나다 순으로 늘어놓고 해당하는 단어가 있는 위치는 1로 두고, 나머지는 모두 0으로 두는 표현을 말합니다. 10개의 단어 중 4번째 위치에 있는 단어라면 `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`이 됩니다.
- **코사인 거리<sup>Cosine Distance</sup>**  
두 벡터 사이의 거리를 각도를 이용해 측정하는 방식으로, 각도의 코사인 값을 사용한다고 하여 코사인 거리라고 합니다.
- **앨런 튜링<sup>Alan Turing</sup>**  
현대 컴퓨터 과학의 개념을 정립한 천재 수학자로, 2차 세계대전이 발발하자 독일군의 암호를 해독하여 연합군이 승리하는 데 큰 기여를 합니다. 이 내용은 영화 〈이미테이션 게임〉에 모티브가 되었으며 영화 제목이기도 한 이미테이션 게임은 바로 그 유명한 튜링 테스트를 말합니다. 튜링 테스트가 언급된 〈계산 기계와 지능〉이라는 논문은 인공지능을 언급한 최초의 논문이기도 하며, 사실상 인공지능의 역사는 튜링 이전과 이후로 나눌 수 있을 정도로 인공지능 역사에서 빼놓을 수 없는 인물입니다.
- **엔드투엔드<sup>End-to-End</sup> 방식**  
입력과 출력이 중간 단계 없이 한번에 진행되는 방식을 말합니다. 중간 과정은 컴퓨터가 모두 자동으로 처리합니다.
- **GPT<sup>Generative Pretrained Transformer</sup>**  
트랜스포머의 디코더를 이용한 자연어 생성 모델입니다. 세계 최고의 인공지능 연구소 중 한 곳인 오픈AI에서 만들었으며, 첫 번째 모델은 GPT, 두 번째는 GPT-2, 세 번째 모델은 GPT-3라는 이름으로 발표합니다. 
- **하이퍼클로바<sup>HyperCLOVA</sup>**  
네이버에서 구축한 자연어 생성 모델로, GPT-3와 유사하지만 학습 데이터 중 한국어 비중이 97%에 달하는, 한국어에 최적화한 언어 모델입니다.
- **구글 미나<sup>Google Meena</sup>**  
구글에서 만든 인공지능 챗봇입니다. 엄청나게 많은 문장을 그대로 학습하여 무슨 주제든 얘기할 수 있는 열린 챗봇입니다. 26억 개의 매개변수를 사용했고 341GB의 텍스트 데이터를 학습했습니다. 사람과 구분이 힘들 정도로 좋은 성능을 보여주었습니다.
- **블렌더 봇<sup>Blender Bot</sup>**  
페이스북에서 만든 인공지능 챗봇입니다. 94억 개의 매개변수를 사용해 15억 건의 대화를 학습했습니다. 여기에 더해 인격과 지식, 공감의 특성을 생성하고 조합해 훨씬 더 폭넓은 대화를 이끌어나갑니다.
- **질의응답<sup>Question Answering</sup>**  
자연어로 입력한 질문에 정답을 한번에 응답하는 기술입니다.
- **버트<sup>BERT</sup>**  
트랜스포머의 인코더를 이용한 자연어 이해 모델입니다. 질의응답에 대표적으로 활용되며, 사람이 자연어로 입력한 질문을 분석하여 정답의 위치를 확률적으로 계산합니다.
- **전이 학습<sup>Transfer Learning</sup>**  
미리 학습해둔 사전지식을 그대로 활용하는 학습 방법입니다. 엄청난 데이터를 매번 학습할 필요 없이 전이 학습을 하면 약간의 학습만 더하면 됩니다.
- **튜링 테스트<sup>Turing Test</sup>**  
기계가 지능을 갖추고 있는지를 판별하고자 하는 시험으로, 튜링이 〈계산 기계와 지능〉이라는 논문에서 제안했습니다.
- **중국어 방<sup>Chinese Room</sup>**  
중국어를 전혀 모르는 사람도 단순히 책에 있는 답변을 찾아내서 통과할 수 있다는 내용으로, 튜링 테스트에 대한 대표적인 비판입니다.
- **레이 커즈와일<sup>Ray Kurzweil</sup>**  
구글에 근무하는 미국의 미래학자로 2029년까지 튜링 테스트를 통과하는 컴퓨터가 나올 것이며, 2045년에는 기계가 인간의 지능을 추월하는 '특이점'이 올 것이라고 예측해 유명해졌습니다. 음악인들에게는 스티비 원더의 제안을 계기로 그랜드 피아노의 소리를 완벽하게 재현해낸 커즈와일 신시사이저를 개발한 것으로 더욱 유명합니다. 지금은 우리나라의 영창 피아노가 커즈와일 신시사이저를 인수하여 생산하고 있습니다.
- **특이점<sup>Singularity</sup>**  
기계가 인간 지능을 추월하는 시점을 의미하며, 커즈와일은 본인의 저서 《특이점이 온다》에서 이를 2045년 전후로 예상했습니다.

# 8장 내비게이션
- **과적합<sup>Overfitting</sup>**  
학습 데이터를 과하게 학습하여 실제 데이터에서는 오히려 오차가 증가하는 것을 말합니다. 어떤 사람이 옆으로 누워 몸을 움츠리고 잔다고 해서 침대를 자세에 맞춰 만드는 것과 유사합니다.
- **오컴의 면도날<sup>Occam's Razor</sup>**  
어떤 현상을 설명할 때 필요 이상의 가정과 개념은 면도날로 베어낼 필요가 있다는 권고입니다. 과학 분야에서 널리 응용하는 일반적인 지침입니다. 과학 분야에서는 복잡한 것보다는 단순한 설명을 선호하고, 간단한 과정으로 다양한 자연현상을 설명할 수 있는 이론을 선호합니다. 최소 비용, 최대 만족이라는 경제적 원리가 여기에도 적용됩니다.[^fn-371]

[^fn-371]: 박상길, 《파이썬 알고리즘 인터뷰》, 2020, 371쪽.

- **의사결정나무<sup>Decision Tree</sup>**  
질문 결과에 따라 여러 갈래로 분기하는 나무 형태의 모델로, 스무고개놀이를 통해 정답을 찾아가는 과정과 비슷합니다.
- **랜덤 포레스트<sup>Random Forest</sup>**  
데이터를 무작위로 추출해 여러 개의 의사결정나무를 만들고 그 결과를 모두 종합하여 정답을 찾는 모델로, 기존 단일 의사결정나무에 비해 오류에 견고하고 성능 또한 훨씬 더 뛰어납니다.
- **그레이디언트 부스팅<sup>Gradient Boosting</sup>**  
랜덤 포레스트는 무작위로 서로 독립적인 여러 개의 의사결정나무를 만들지만 그레이디언트 부스팅은 이전에 만든 나무를 개선해 새로운 의사결정나무를 만듭니다. 각각의 나무는 이전과 달리 독립적이지 않으며 오히려 이전의 나무에 크게 영향을 받습니다. 이전에 만든 나무에서 오류가 발생하면 실수를 바로잡는 새로운 나무를 만드는 과정을 오류를 최소화할 때까지 계속해서 반복합니다.
- **데이크스트라 알고리즘<sup>Dijkstra's Algorithm</sup>**  
최단 경로를 찾는 가장 유명한 알고리즘으로, 1956년 네덜란드의 컴퓨터과학자 에츠허르 데이크스트라가 여자친구와 함께 커피숍에 갔다가 20분 만에 만든 알고리즘입니다. 커피숍에서 냅킨에 적을 수 있을 만큼, 오컴의 면도날을 증명하는 대표적인 알고리즘입니다.
- **`A*` 알고리즘**  
데이크스트라 알고리즘은 최단 경로를 찾기 위해 주변의 너무 많은 경로를 탐색합니다. `A*` 알고리즘은 출발지에서 도착지로 이동하는 시간뿐만 아니라 반대 방향, 즉 도착지에서 출발지로 거꾸로 이동하는 시간을 포함한 여러 정보를 함께 반영하여 탐색 횟수를 대폭 줄인 알고리즘입니다.
- **브라에스 역설<sup>Braess's Paradox</sup>**  
새로운 도로가 건설되면 더 빠르게 이동할 수 있을 것 같지만 새로 만든 도로에 차량들이 몰리면서 교통 전체 상황이 도로 개통 이전보다 더욱 악화되는 역설적인 상황을 말합니다.

# 9장 추천
<img src="https://lh3.googleusercontent.com/pw/AM-JKLU70p7k4r6cD-GnpQXnAdmHGmiDRqHnDpBWaM_sE6Rs0y6PHKWkAo97oMNXNNkZWkiWTq1R3JtynBIEIqGx41Vx6cvATmvi-INzQ5agIM4Di6-LH0B1CU-yapFJCre2gIirOq8DSsokuoxIKmrckhnCSQ=w670-h226-no?authuser=0" width="70%">

- **넷플릭스 프라이즈<sup>Netflix Prize</sup>**  
넷플릭스는 고객이 영화에 부여한 별점 데이터 1억 건을 공개하고 이 데이터를 이용해 고객이 아직 보지 않은 영화에 대해 부여할 별점을 예측하는 대회를 100만 달러의 상금을 걸고 개최했습니다. 수많은 데이터 과학자가 이 대회에 참여했고 여기서 나온 다양한 추천 알고리즘은 이후 추천 분야의 발전을 이끌며 넷플릭스 하면 추천 시스템을 떠올리게 하는 계기가 됩니다.
- **장바구니 분석<sup>Market Basket Analysis</sup>**  
고객의 구매 내역을 분석해 가치를 이끌어내는 연구 분야입니다. 기저귀를 사는 고객은 맥주를 함께 구매한다는 사실을 알아냈고 이후 쇼핑센터에서는 기저귀 매대 근처에 맥주를 진열해 매출을 늘릴 수 있었습니다.
- **데이터 마이닝<sup>Data Mining</sup>**  
대규모 데이터에서 어떤 특정한 패턴을 발견하고 추출하는 행위로, 마이닝이 광산에서 금과 같은 소량의 유용한 가치를 발굴하는 것처럼 데이터 마이닝 또한 데이터에서 의미 있는 핵심 가치를 발굴해냅니다.
- **콘텐츠 기반 필터링<sup>Content-Based Filtering</sup>**  
고객이 선호하는 영화와 유사한 영화를 추천하는 방식입니다. 예를 들어 액션 영화를 선호하면 또 다른 액션 영화를, 공포 영화를 선호하면 또 다른 공포 영화를 추천하는 식입니다.
- **협업 필터링<sup>Collaborative Filtering</sup>**  
선호하는 영화 자체의 특징에 집중하기보다는 범위를 좀 더 확장하여 유사한 고객의 정보를 활용하는 방식입니다. 액션 영화를 즐겨 보는 고객이 전쟁 영화도 많이 본다는 고객 정보를 기반으로 유사한 액션 영화 고객에게 전쟁 영화를 추천하는 식입니다.
- **행렬 인수분해<sup>Matrix Factorization</sup>**  
고객이 부여한 평점 정보를 기반으로 고객의 특징을 자동으로 추출하고 영화의 특징도 자동으로 추출하여 이 정보를 바탕으로 고객의 평점을 예측합니다. 넷플릭스 프라이즈에 참여했던 사이먼 펑크가 고안한 알고리즘으로 매우 좋은 성능을 보였으며, 어느 날 자신이 사용한 알고리즘을 블로그에 모두 공개한 채 홀연히 떠나 더욱 유명해졌습니다.
- **잠재요인<sup>Latent Factors</sup>**  
행렬 인수분해는 고객의 특징과 영화의 특징을 추출하는데, 수많은 특징을 일일이 추출하고 매번 값을 수동으로 정의하기 어렵기 때문에 평점 정보를 기반으로 모두 자동으로 진행합니다. 이처럼 숨어 있는 특징을 자동으로 추출하는 것을 잠재요인을 발굴해낸다고 표현합니다.
- **차원의 저주<sup>Curse of Dimensionality</sup>**  
특징을 많이 추출하면 좋을 것 같지만 사실 특징이 하나 더 늘어날 때마다 필요한 데이터는 기하급수적으로 늘어납니다. 만약 데이터가 부족하다면 오히려 제대로 특징을 추출해내지 못하고 성능이 더 떨어지는 '저주'를 받을 수 있습니다.
- **콜드 스타트<sup>Cold Start</sup>**  
말 그대로 차갑게 시작한다는 의미로, 새로 올라온 영상은 조회수도 없고 인기가 있을지 알아낼 만한 정보가 거의 없기 때문에 추천 영상에 올리기가 매우 어렵습니다. 추천 시스템의 어려운 문제이기도 합니다.

# 판매처
<img src="/images/2024/20241018171507001040.png" width="50%">

《비전공자도 이해할 수 있는 AI 지식》은 다음 판매처에서 구매하실 수 있습니다.
- [교보문고](https://product.kyobobook.co.kr/detail/S000214507019)
- [YES24](https://www.yes24.com/Product/Goods/134766939)
- [알라딘](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=349374326)
- [영풍문고](https://www.ypbooks.co.kr/books/202410119088692838)

및 전국 대형서점
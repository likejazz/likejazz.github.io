---
layout: post
title: ! 'io.net 사용 후기'
tags: ["Large Language Model (LLM)"]
last_modified_at: 2024/10/24 13:11:06
---

<div class="message">
io.net을 직접 사용해보고 경험을 정리한다.
</div>

<small>
*Sep 25, 2024*
</small>

- [개요](#개요)
- [내용](#내용)
  - [클터스터 생성](#클터스터-생성)
  - [학습 진행](#학습-진행)
  - [워커 참여 불가능](#워커-참여-불가능)
- [결론](#결론)
- [의견](#의견)

# 개요

io.net을 직접 사용해보고 경험을 정리한다.

# 내용
## 클터스터 생성

기본적으로 다음 2종류의 클러스터를 지원한다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNkbSqqflFVUKgaidQXafJ17_4PNwIzhKLvajxhhVD_DZjk0Nor2E4iDCLssCSUwv0zH_A9J461w9h_-V8kLlsqxGZqtKzcGI0BmR7DOw_Zh9HD5wl1BiEbFoj8U4_aatrL8Mf_9R2PiFv9ew5IZdYeug=w1216-h1646-s-no-gm?authuser=0" width="300px">

사실상 Ray만 지원하며, 이 중 Mega-Ray는 이름 그대로 수 천대의 Ray Cluster를 한번에 설정해주는데, 최소 결제 금액이 수천달러에 달해서 사용해보지 못했다. 또한 노드 관리의 편의를 위해서는 K8s와 모델의 분산 학습을 위해서는 PyTorch FSDP 네트워크를 지원할 계획이 있는 것 같은데 아직 지원하진 않는다.

사실상 유일한 옵션인 Ray를 선택하면 이제 다음과 같이 클러스터 타입을 선택하는 화면이 나온다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczM2cX79NhEpZOaINvhtXU2SQyAoF2XXxU-ljvVbed5S_7ytTSWozJEjBUnrWynaWjjBPndhQYCH-kE20MNpIFmgrHsPVBbRNR-C0yjhIQGvpM23sU_lwqd5qOp3BOMTWT_wX0_FGchu43scwF3rZQU_cQ=w2700-h1566-s-no-gm?authuser=0" width="500px">

Train 또는 Inference에 따라 각 용도에 맞는 네트워크 속도 등을 자동으로 구성해주는듯 한데 차이점은 잘 모르겠다. 어차피 이후에 네트워크 속도나 노드 갯수는 별도로 설정이 가능하다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczOtfTLpSybWDcotlcuweLdaOyXk_ZfubICWCWsZDmQhvwZqjWGPwT2OMO6UFFzODVUiv6I3ZKwozWAyiK6NWNcnWyewRLu11B-BBby2C1JwMOMRGYIhaXCL3bvAajfS8lyHNstz4M1JNm2R3GH_aw7fJg=w1548-h710-s-no-gm?authuser=0" width="500px">

다른 supplier도 선택할 수 있는데 사실상 대부분의 노드는 io.net으로 제공되기 때문에 render network로는 사용이 어렵다. 우리나라는 render network에 딱 1노드만 있으며, 게다가 GPU 3장 이하라 아예 클러스터를 생성할 수 없다는 에러가 발생한다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczO24TLwoSFUonMCfdy4nTJ1AtFanZ3Q7mzfje0y8NDaPLkgJ2hFBhF8EowwMi7244lKygc88cIk9Fq7rm4KtJpySlCubvITTkYuOlHbEt5xBjkPQ5tLv4j2mSSQ9EqQS6809VZo4L9pp-6NB7LJhm7G3A=w2630-h478-s-no-gm?authuser=0" width="500px">

io.net은 우리나라에서만 300장이 넘는 GPU를 확보하고 있다. 참고로 미국을 선택하면 무려 9,717장으로 표시된다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNsBYCNF1gD6n5uOW7GZJGDaK9y64jCjq3z7K-ccpGb3lzyye1ZMDDed9bIwV9ZaRjX1mWRg-yqXjP1r348lRB_P8D5TCJltb_iy39_erFImmb4ThKewCJNX8a-fTCUG9zk6hpjHA3Wi7Dv7UUpbFdVLQ=w2676-h1152-s-no-gm?authuser=0" width="500px">

접속 속도에 따라 제공되는 GPU 갯수가 다르다. 예를 들어 가장 빠른 Ultra High Speed에서는 우리나라에서 75장만 보인다. 그런데 이 정도 속도라면 가정용으로는 불가능하고 IDC에 있을 것으로 추정되는데, 이는 결국 가정용 GPU로 분산된 노드를 클러스터로 구성하겠다는 당초 취지와 달리 결국 IDC에 있는 엔터프라이즈 GPU를 사용한다는 얘기 아닌가?

<img src="https://lh3.googleusercontent.com/pw/AP1GczOGZ5ZLaQW0eLKJF_Fk5ZSLabyxakYl-vW7miuILJKmds6smNsIsrTXoMzw0YWNZdCJK34JlwOWLwFCVh2QuswWQTVQqW1TZnV5dCaqDfUWOYDqSIyvY1P79ZWW1GrqmazBvHQx7YG6gRIA46MJo6Aa-g=w2628-h1062-s-no-gm?authuser=0" width="500px">

A100은 18장(40G 모델)이 있고, 4090은 8장이 있다. 서로 섞어서 노드를 구성할 수는 없고 동일한 GPU 스펙으로만 가능하다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPnGNGAWKEeyQznvoEAX6zs0KlbOXNd1DKHut-eRNnU3u4bHC7JMkfmG8w6QL5XNipCn7zfGrX5x06Y5rm_L-2P07XDM-km7YLcdsWKQxXq3hKQ_SY8AltV8FEO7tSt7Urlphma7N4vgjKaRJMknz4vQA=w2744-h1398-s-no-gm?authuser=0" width="500px">

어떤 이미지를 배포할 것인지 묻는데, 마찬가지로 Ray밖에 사용할 수 없다. Ray를 선택하면 다음과 같이 Master 설정화면이 나온다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNUox8DLnDF1IkHCyn8wlLrVT3yUeaEAedwuLvwHAi2ihpyzdP5EZXY05pGnZzLkI8hxFX8lFLpCI-lFOOs-Sd-R_7BAgkpq3nOSMCKNyzy9Fr5NUFXFjIvwKysvvd7EgiPAxrQuV6nEK_kei0F41RYxw=w1694-h1414-s-no-gm?authuser=0" width="500px">

Ray Cluster는 사용자가 제공하는 노드만으로는 클러스터를 구성할 수 없다. 반드시 Master가 필요하며, 이는 io.net측에서 AWS등을 이용해(확실하지 않음) 제공하는 것으로 보인다. Master는 학습에 참여하지 않기 때문에 GPU가 필요없으나 기본적으로 A4000으로 보이며, 생뚱맞게 서버 위치는 네덜란드로 나온다. 참고로 노드는 모두 South Korea에 위치해 있다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPq_ZcOVE8b_Rv4EbxNuCHQKfHbUQK_ALpIJIe8kqu3d6_-3HvRDmlr5Uk6AyB0-r0Tr7lv_l7sGuV3HEhBpbO_o4Fv8FV6kRh1tiCzJfb79mUT8DinsKgkqd7ZtzAUhp7m7pCiUkiBUYoWFyIEaGhAbQ=w2858-h1260-s-no-gm?authuser=0" width="500px">

이제 결제를 해야 하는데 여기서 부터 엄청난 난관이 기다리고 있었다. 왜냐면 얘네들이 사용하는 전용 코인인 IO로만 결제가 가능했기 때문이다. 또한 처음에는 전용 지갑이 필요하기 때문에 일단 지갑도 생성해야 했다. 다행히 지갑은 잘 생성했으나 결제 화면에서 어쩔 수 없이 다음과 같이 돈이 부족하다는 오류를 마주하고 말았다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczM2y2VKNGkQ74knC4PUckw4jclfoLnpqTTN-iwioBvywGXWxeWmRagqQdmooBVyfzR7huUXZxYxbnMzDBatAx4Xti_iV0H-FaKFNxnKHQ_omuEgSq5grq4PyJC2hl8_RmcMnSne3b_zrPwdZDNjE0H-Tg=w1098-h1180-s-no-gm?authuser=0" width="400px">

A100-40G 32장을 1시간 사용하는 것으로 예약했고, 20 IO가 필요하다고 하는데 저 IO라는 단위의 의미도 잘 모르겠고 어떻게 구매하는지도 알 수가 없었다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPtsXVcy4QrTtPUylPWLcnYcQ7PvaTRobxsa21ErCV1jKrd89ZcCtRJbE2_pzB5jVFs0DIAY7b3F0CN1WLuV6SIaLz9XQRLh8PXH3kBQgTSpeaN0Mqp-RHqQTqtzLCKSzYfcu1Ut_z_a3MMIjq9xp7wgg=w1384-h1032-s-no-gm?authuser=0" width="500px">

다행히 MoonPay라는 서비스에서 달러로 구매할 수 있다며 예상 비용을 산출해주는데 무려 $3200가 나왔다. 코인에 대한 지식이 없다보니 아마 엉뚱한 코인을 잘못 선택한 것 같다. 변동성이 큰 코인 답게 1분 단위로 청구 금액이 계속 변하는 것이 인상적이었다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNY_ulQgXTg8NmuUqcVUwo2HTUUI5czYP7lVxfNezvdk687B9y6AMssADPv6jQ_QeEgbzt49V5_PGIdMXVGRTnCsYsXP-HNv4aym8_Q7A31E4fIcjUEiYL8JcQjBLU3_t4EC7ZeRh050gWmLd6dDz-9XQ=w1544-h1266-s-no-gm?authuser=0" width="500px">

다행히 이전 화면으로 돌아가보니 달러로 구매할 수 있는 옵션이 존재했다. 우측 USDC이며, 대신 2%의 수수료를 받는다. 수수료가 아까웠지만 코인을 어디서 구매해서 어떻게 지갑에 넣는지도 모르기 때문에 편하게 신용카드로 결제했다. 참고로 내 계정에서 개인카드로 진행했고 이미 Stripe에 내 신용카드 정보가 등록되어 있었기 때문에 1-click으로 바로 결제가 진행됐다.

아울러 GPU 갯수 선택 화면을 보면 4장, 5장, 8장, 9장, 13장 이런식으로 이상한 단위로 점프하는데 이는 노드 단위로 클러스터를 구성하기 때문에 발생하는 현상이다. 즉 GPU 4장 노드와 1장 노드가 섞여 있고, 노드 전체를 임대하기 때문에 4장 노드+1장 노드, 4장 노드+4장 노드+1장 노드 이런식으로 클러스터가 구성 되는 것이다. 참고로 최소 갯수가 4장이므로 1장 노드만으로는 구성할 수 없지만 4장 노드만으로는 가능하다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczMycne6cDBagOCL_rkHpiE9PNDHtzDwIj4OPWtEGXqh1ezi7oYaHp6YM-mxoZaW9D0U9sPCBwok8n1RbRwjpUacgOveswnkFEGlC33JriTnjf19q_nvLbh7WZ6hmSL3H36c47RH3TKrOcbk5I-FngZdgQ=w2186-h1220-s-no-gm?authuser=0" width="500px">

결제를 마쳤더니 드디어 클러스터를 생성해준다. 참고로 실험 비용을 줄이기 위해 좀 더 저렴한 RTX 4090 4장으로 변경해서 요청했다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPD8NR73VU7RXB8W-1eAmS7BxsJsS1JfJoeq7YzRl4CDRhkHZeztGRwuGascZnP2Jk8Nd7Ph7Svca2Nx1JVlSfyJtNhvYz-ww_M-fJBNUviYF0m7-WknXoPGGko0AEC-MH4Yn1tGc6KE6vkRoc4bhZGew=w2850-h1728-s-no-gm?authuser=0" width="500px">

드디어 클러스터가 생성됐다.

GPU 4장을 요청했는데 단일 노드는 아니었고, GPU 3장 노드와 1장 노드 이렇게 2노드가 참여했다.

## 학습 진행

이제 실제로 클러스터에 접속하고 학습을 진행해볼 차례다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczODWOf3TYwCVcJQ5rkUYp7s-yujKQ4vH7m1gQ8P5FMASwXFHgKlHPj2V9xQLabRE_ouuaeFqrgxZMEBmu0d4FCA3zjPj-40jTD3Cc8zdwZeihn604Ec5AQlH34OPQK6_Ww-3mDyTY1J38avXHb6nzvjNg=w1956-h1698-s-no-gm?authuser=0" width="500px">

vscode와 jupyter를 지원한다. 우리가 사용하는 kubeflow와 동일하다. vscode로 들어가서 터미널을 열어보니 Master 노드에 접속된 상태이며, nvidia-smi는 당연히 지원하지 않았다. 대신 `ray status`로 노드 상태를 보여줬다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczN4SDcT_BSVcKYHKSZ6FQNK-d6a2O5dt4revEp_uVn5InuE3j4rz8RJSo2GNgdPMRBCyhE05fSK2p-wffq2JfO30tuEwA_AC_gwtpPZpj5mgk_2s2U08j_36irnR41DTulGHCFTooc5gYQqd8TstE2GKA=w2528-h1668-s-no-gm?authuser=0" width="500px">

실제로 [Ray 샘플](https://docs.ray.io/en/latest/train/examples/accelerate/accelerate_example.html)로 학습을 진행해봤다. huggingface의 [accelerate를 이용하는 간단한 샘플](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)의 변형인데, Ray를 위해서 수정해야 할 부분이 많다. 이처럼 torch 수준에서 변경해야 할 사항이 많은 점은 ray의 가장 큰 단점이다. 최근에 LLM fine-tuning은 torch > tranformers (trainer) > llama-factory 순으로 추상화되어 있는데 이처럼 torch에서 수정하게 되면 이후 패키지에서도 모두 수정해야 하는 어려움이 존재한다. 유명한 패키지인 경우 각 패키지가 공식적으로 패치를 제공하지만 Ray의 경우 transformers의 trainer가 지원하지 않기 때문에 개별 패치가 필요하다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczOftxQiU-7Zq0Ry5zl09aMwoYhU7HRb1ymKST-B_45WlAMo26DCgW78gcu4rrvquhSMZIr931czmN7NggTx7HzjGtHYJ2ZwUoqSD9S2_Gc72fZM2Iz_QYuxfUlzvgtW8tCPjEgVNTthlG2izCfkjPJbhg=w2082-h988-s-no-gm?authuser=0" width="500px">

그렇게 학습을 진행했음에도 이후 진행 여부를 명확하게 파악할 수 없었다. 이부분은 Ray에 대한 경험이 부족해서 그런것으로 보인다. Ray에 충분히 익숙해지면 잘 사용할 수 있을듯 한데, 현재는 사용해본 경험이 거의 없다보니 시행착오가 적지 않다. 아마 딥러닝으로 학습하는 연구자들은 대부분 Ray에 대한 경험이 없을 것이다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNcnGXwFuH12NhdUbXiOoxwe7otZxlK3eVj2gvkp0MVwYnaavDvsYecyfmgnaJJ_MJB4AyWggemG01sRKbpCW-3cD03PR5Sk1uh3pIphAPX7PNjuIbxioEgUS4mYPCjvjEYrkpBI79vrZBdLzsQTov-jQ=w2708-h1668-s-no-gm?authuser=0" width="500px">

이처럼 dashboard에서는 전체 노드의 상태와 현재 진행 중인 job을 보여준다. 03000000이 간단한 샘플을 실행시킨 job이며 현재 돌고 있다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNDvHOhQzf2dEizOfO3BE1GQjuBWafSvAvPolhhooZDTQ1JrDpQAF--VPSd541OuC2G2uz8NMSp8U-rF0JSuNLMCULpoSM_R3lPckCoAskghnTWvMT6eRE3sNSPCZNHszVxC8wE9nqhZAZjv4aGfojSPQ=w2772-h1502-s-no-gm?authuser=0" width="500px">

실제 노드의 상태도 조회해볼 수 있는데 이처럼 이름도 보이고 (docker-desktop과 4090) GPU를 얼마나 점유하는지도 잘 보여준다. 4장 모두 100% 사용 중이다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPg-x1qEnkqzafbK0DNt2M9s9-CdbLduvlOQ7fZi6rNxW6itgB7o--M92dKKgXeuGHvQMgpML3c2M7mOg1xuMHHzSYVuSc6JX4z35RScSwo4BNObUuTjJb-hsqQZOT2WRjJsJz5iWs50A-jALhZJ4NEIQ=w2526-h960-s-no-gm?authuser=0" width="500px">

좀 더 우측에는 각 노드별 리소스를 보여주는데, 노드 별 메모리, disk가 모두 제각각이다. GPU만 동일하고 다른 자원은 이처럼 저마다 제각각이다. 또한 더 우측에는 네트워크 사용량도 보여준다. 1번 노드가 뭔가 많이 전송하고 있음을 알 수 있다. huggingface의 accelerate로 실행한 job이므로 아마 DDP로 동작하고 있을 것이다. 이 경우 각 모델은 모두 단일 GPU에 올라가야 하며, 데이터만 서로 분산해서 학습하고 backward시 gradient만 전달하는 형태로 동작한다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNELhFPSGd0DJNpCDKMDHd8qaPLX3VZuE0L7SQAYsHnkagqMVpZeOWkfUTliKV8Cb4nSu3EEPxm0hHdkwzrs5udpu2acG5aif3Zk2aran7js4RkwCxRBIfJGkg6VqpqzpPSHC8zIx8ztFSi4XPdSqZGGg=w2804-h1630-s-no-gm?authuser=0" width="500px">

노드를 좀 더 상세히 살펴보면 uptime 표시와 함께 얼마나 신뢰할 수 있는 노드인지도 보여준다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczPdDRteFx3SLab32zvp7f325wrQvsGycWFvopfuSYOweNmtrYER9PiJiEY62N5MZl9ad2zFPvJqCMqKxfWNvP0asXX9U02vzdLU_3Hf9Q7jb1x9kluQr_2Z7jpTdMYZba5H5b-EcQFqARNaSCTREu14NA=w1848-h1466-s-no-gm?authuser=0" width="500px">

코인 reward를 얼마나 수령했는지도 보여준다. 블록체인에 기입되므로 이 정보는 영원히 남게될 것이다. 

그런데 이렇게 노드 상태를 살피다가 정작 예약한 1시간이 지나도록 학습을 완료하지 못했다. 간단한 예제이므로 금방 수행되어야 하나 Ray에서 에러가 발생한 것으로 보이며 제대로 인지할 수 없었다. 에러를 명확히 보여주지 않았고, 어디서 에러가 나는지도 찾을 수 없었다. 결국 1시간 동안 원인을 밝혀내지 못한채 그냥 job이 종료되고 말았다.

<img src="https://lh3.googleusercontent.com/pw/AP1GczNwN_vXE8nMSlEIYmWR26KVrCM_LGRzdy8ClfksovPaApBi88XmbG7URIpN8nyH-dNnpgD8EwN3YDpnUHgEZb6_9i8Kjs75KUTaqvmVtHdd39jhl_Tm82YiUOFH5I3PMrjQURxCk7M9OfiDMxx5bjAGUg=w3034-h1818-s-no-gm?authuser=0" width="700">

이후에 동일한 예제를 DGX에서 따로 실행해봤을 때는 10초 만에 결과를 받아볼 수 있었다. 이렇게 간단하게 실행되는 코드를 io.net을 이용하게 되면 번거롭게 코드를 수정해야 하고 (이게 가장 높은 장벽) 클러스터 설정이 필요하며, Ray에도 익숙해서 잘 동작하는지 판별할 수 있어야 (두 번째 높은 장벽) 한다. 여러모로 제대로 사용하기가 쉽지 않다.

## 워커 참여 불가능

<img src="https://lh3.googleusercontent.com/pw/AP1GczMmydI0FaS4H0_wquZbv2UhV42h5HTjxmD6b57_t4jJ8HlKpKpIYnjie8h2SwNUxikKwRn0U87JwDlko6cC6yGUsRyUn6HkEWRamIUrkl1s1M6OHT98zwemYO2WIk2GlYjFMLuh8ovilDFePpzhe_c1dA=w1222-h634-s-no-gm?authuser=0" width="500px">

게다가 현재는 더 이상 워커로 참여할 수 없다. 아마 참여하겠다는 사람은 많은데 실제로 돈을 내고 쓰는 사람은 별로 없는 공급 과잉 상태가 아닌가 싶다. 나 또한 한번 경험해보고 나서 굳이 돈을 내면서까지 다시 쓸 생각은 전혀 없다. 대부분의 연구자들은 시행착오를 줄이는게 중요하고 그래서 시간을 아끼는게 무엇보다 가장 중요하다. 그래서 AMD가 있음에도 어디서나 잘 돌아가는 NVIDIA를 사용하는 것이고, 실험적인 패키지 보다는 검증된 패키지를 찾게 되는 것인데, io.net은 그 자체로 여러 장벽이 존재하기 때문에 이를 넘어서기가 쉽지 않을 것이다.

# 결론
1. 결제단계를 넘어서기 쉽지 않다. 
  - 실제로 학습을 희망하는 사람들은 빠르게 결재하고 당장 사용하고 싶을텐데 번거롭게 코인을 구매해와서 결제해야 한다.
  - 다행히 수수료를 부담하면 달러로 결제가 가능하다.
  - 코인 결제 방식이기 때문에 변동성이 매우 크다. 어느날은 $4였다가 어느날은 그 절반인 $2가 되기도 한다.
2. Ray에 맞춰 학습 코드 수정이 필요하다.
  - 논문을 실험하기 위해서 어디선가 코드를 가져왔다고 가정해보자. 이때 이 코드 그대로 돌아가길 원하는데 어딘가를 수정해야 한다면 정말 난감한 상황이 된다. 내가 작성한 코드도 아니며 아직 동작 원리도 파악하지 못한 상태인데, 수정이 필요한다면 그 자체로 큰 장벽이다. 게다가 한번에 잘 수정된다는 보장도 없다. 분명 다양한 시행착오를 겪게 될 것이다.
3. Ray에 익숙해야 한다. 
  - Ray는 열심히 개발되고 있지만 아직 인지도가 낮고 ML 연구자들에게 대중화되지 못한 상태다. 분산 컴퓨팅 분야는 기존에는 Slurm이, 최근에는 K8s가 많이 쓰이고 있다. 게다가 상용 스케줄러도 다양하게 출시되어 있는 상태에서 Ray에 익숙한 연구자들은 여전히 극소수다.
4. 굳이 Ray를 쓰겠다면 io.net 같은 블록체인 기반 보다는 Ray를 만든 개발사가 직접 제공하는 신뢰할 수 있는 Anyscale Cloud를 쓰는게 낫지 않을까? 
  - 특히 기업 사용자들이 굳이 블록체인을 써야할 당위성이 부족하다. 굳이 블록체인이어야 하는가? 굳이 탈중앙화여야 하는가? ML 모델을 학습하는데 도대체 그런게 왜 필요한가? 유일한 이유를 대자면 저렴한 가격이 있겠지만 이 또한 RunPod 같은 서비스가 훨씬 더 경쟁력 있는 가격을 제시한다.
  - 같은 맥락으로 io.net이라는 서비스 또한 코인 상장이 목적이고 네트워크는 그저 들러리가 아니었나 싶다. 그리고 이들은 상장을 했기 때문에 결국 목적을 달성했다.
5. 모델 및 GPU 분산을 지원하지 않는다.
  - huggingface의 accelerate를 Ray에서 wrapping한 버전만 지원하며 기본적으로 DDP로 동작할 것이다. Ray Train이 FSDP 또는 DeepSpeed를 지원할 수 있을 것으로 보이지만 활용 사례는 찾기 어려우며, 기본적으로 Ray는 data parallel을 통한 분산 학습에 최적화되어 있다. 이처럼 기본적으로 모델 분산이 first-class citizen은 아니며, 심지어 GPU 분산도 지원하지 않는다. 1노드에 GPU 4장이 있다면 통째로 제공되는 형태로, 1장씩 나눠서 다른 클러스터에 제공되는 형태가 아니다. 또한 동일한 GPU끼리만 클러스터 구성이 가능하며, A100 + RTX4090 같은 형태는 불가능하다.

# 의견
1. 결제 방식 개선
  - 신용카드로 자유로운 결제를 우선으로 하여 코인에 관심 없는 일반 사용자도 편리하게 이용할 수 있도록 해야한다.
2. Ray 의존성 탈피
  - 네트워크를 제대로 활용하기 위해서는 Ray에 맞춰 코드 수정이 필요하며, Ray 구조에 대한 충분한 이해가 필요하다. Ray 의존성 없이도 기존 멀티 노드 학습하듯, 코드 수정없이 바로 실행 되어야 한다.
3. 모델 및 GPU 분산 지원
  - 기본적으로 여러 장의 GPU에 모델 분산을 지원하지 않는다. 단일 GPU에 모델 전체가 올라가는 구조이며, 각 노드 또한 GPU 단위로는 다른 클러스터에 제공될 수 없으며 노드 전체가 단일 클러스터로 제공된다.
4. 이기종 GPU 지원
  - 동일 GPU끼리만 구성이 가능하다. 이렇게 되면 RTX를 보유한 노드는 RTX가 학습에 투입될 때만 사용할 수 있다. H100이 투입될 때도 RTX가 일부 역할을 해줄 수 있도록 이기종<sup>Heterogeneous</sup> 분산 구현이 되어야 한다.
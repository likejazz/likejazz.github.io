---
layout: wiki 
title: NPU
tags: ["MLOps & HPC"]
last_modified_at: 2024/05/08 15:21:46
---

- [HyperAccel](#hyperaccel)
- [Grayskull](#grayskull)

# HyperAccel
허깅페이스와 인터페이스를 동일하게 맞췄다. 당연히 내부 구현은 당연히 전혀 다르다. nvidia-smi와 유사한 hyperdex-smi가 있다. GPU와 관련 없는 tokenizer는 허깅페이스를 그대로 활용한다. `load_model()` 같은 함수는 hrt라는 이름으로 하드웨어를 직접 제어하는 모듈을 개발해서 이를 통해 자사 NPU 메모리에 직접 올리는 형태로 구현되어 있다. torch의 기능도 일부 사용하지만 CPU 전용으로 설치됐다.

# Grayskull
tt-buda의 경우 허깅페이스 모델을 컨버팅 없이도 그대로 실행시켜주는 점이 인상적이었다. 그러나 구동 가능한 모델이 제한적이고, 앞뒤로 warm-up 시간이 너무 길어 제대로 환경을 갖춘 프로덕션 환경에서나 제한적으로 사용이 가능해 보였다. tensorflow의 좀 더 무거운 버전을 보는 느낌이다. 다행히 tt-metal을 추가로 제공해줘서 여기서는 JIT 방식으로 간편하게 활용할 수 있지만 그래도 device를 가져와서 open하는 방식이 조금 불편했고, 그나마 지원하는 LLM인 Falcon 7B 데모도 메모리 오류로 실행되지 않았다. 논문 등을 쓸 때 하나씩 실험하는 용도로 활용할 수 있을 것 같지만 이 또한 GPU에 비해 잇점이 별로 없다. 그나마 tt-metal은 커뮤니티가 매우 활성화 되어 있어 사람들이 다양한 방식으로 응용을 시도하고 있다. 주요 라이브러리가 모두 오픈소스로 진행되고, 네임드가 대표로 있는 회사다 보니 이런 부분은 잘 진행되고 있는 것으로 보인다.
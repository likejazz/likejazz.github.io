---
layout: wiki 
title: 통계학 책
tags: ["Books"]
last_modified_at: 2022/02/20 23:47:23
---

<!-- TOC -->

- [신도 주사위 놀이를 한다 <sup>2019, 2020</sup>](#신도-주사위-놀이를-한다-sup2019-2020sup)
- [데이터를 분석해 <sup>2019</sup>](#데이터를-분석해-sup2019sup)
- [숫자에 약한 사람들을 위한 통계학 수업 <sup>2019, 2020</sup>](#숫자에-약한-사람들을-위한-통계학-수업-sup2019-2020sup)
- [처음 시작하는 만화 통계학 <sup>2012, 2020</sup>](#처음-시작하는-만화-통계학-sup2012-2020sup)
- [통계의 아름다움 <sup>2019, 2020</sup>](#통계의-아름다움-sup2019-2020sup)
- [숫자가 만만해지는 책 <sup>2018, 2020</sup>](#숫자가-만만해지는-책-sup2018-2020sup)
- [통계학을 떠받치는 일곱기둥 이야기 <sub>2016</sub>](#통계학을-떠받치는-일곱기둥-이야기-sub2016sub)
- [좋은 선택, 나쁜 선택 <sub>2019</sub>](#좋은-선택-나쁜-선택-sub2019sub)
- [누구나 파이썬 통계분석 <sub>2018, 2020</sub>](#누구나-파이썬-통계분석-sub2018-2020sub)
- [신호와 소음 <sup>2012, 2020, 2021</sup>](#신호와-소음-sup2012-2020-2021sup)

<!-- /TOC -->

# 신도 주사위 놀이를 한다 <sup>2019, 2020</sup>
★★★★☆  

- p101. 르장드르는 모든 오차를 제곱한 뒤에 더했다. '진실에 가장 가까운 상태를 드러내기에 적합한' 방법이라고 말하며 최소 제곱법 <sup>method of least squares</sup>이라 명명했다.
- 의료 통계를 설명하는 장으로, 시험 <sup>trial</sup> 계획을 수립하는 방법이 나온다. p277. 무작위성. 1) 어떤 환자가 진짜 약을 받고 누가 위약(가짜약 <sup>placebo</sup>)을 받을지를 무작위로 결정해야 한다. 2) 시험 대상자들이 진짜 약을 받았는지 여부를 모르게 한다.
- p279. 가장 중요한 인물은 로탐스테드에서 일했던 농학자 겸 경제학자 로널드 피셔다. 그가 저술한 『실험 계획의 원리』는 임상 시험의 여러 중심 아이디어의 기반이 되었으며 오늘날에도 광범위하게 사용되는 다수의 기본 통계 도구를 다루었다. (번역체)
    - 통계 자료 분석에는 두 가지 중요한 붕법이 있다. 1) 모수 통계 <sup>parametric statistics</sup>는 수치 파라미터(평균과 분산 같은)를 포함하는 다양한 확률 분포(이항 분포, 정규 분포 등)를 사용해 데이터를 모델화한다. 모수 통계 목적은 파라미터 값을 찾아내는 것. 2) 비모수 통계 <sup>non-parametric statistics</sup>는 명시적인 모델을 사용하지 않고 오직 데이터에 의존. 막대그래프가 간단한 예다. 데이터와 모델이 잘 일치할 때는 모수 통계 쪽이 낫고, 비모수 통계는 상대적으로 유연하며 부적절할 수 있는 가정을 세우지 않는다.
- p285. 운전 교육에서 수강한 과목 수가 합격 가능성에 영향을 주는지 알아내려 한다고 가정할때 직선 모델의 타당성이 별로 없다. (번역체) 1958년에 데이비드 콕스는 로지스틱 회귀를 사용하자고 제안했다.
    - p287. 부트스트랩은 동일 데이터에 대한 표본 재추출에 기초하며, 무작위 표본을 선택해 평균을 계산하고 그에 따른 평균치들의 분포를 찾아낸다.

우리의 베이지안 뇌
- p322. 인간의 뇌에는 약 1000억 개의 신경 세포와 100조 개가 넘는 접합부가 존재한다. (접합부 라는 번역은 synapse를 의미하는듯)
- p328. 힌튼은 1983년에 인간의 뇌가 외부 세계를 관찰하면서 마주치는 불확실성에 대해 판단하고 결정을 내리는 기계라고 말했다. uncertainly  
이러한 아이디어는 1990년대에 확률 이론에 기초한 모델이 되어 헬름홀츠 기계라는 개념으로 구현되었다.
- p331. 착시현상의 가장 유명한 그림은 제스트로의 토끼/오리
    - p343. 왜 우리는 쉽사리 가짜 뉴스에 조종당할까? 그것은 오래전부터 내재한 믿음에 기초하여 작동하는 베이지안 뇌 때문이다. 믿음이 강할수록, 아니면 단지 믿기를 원할 때도 믿음이 더욱 확고해진다.

- p352. 빛 또한 전자기 파동이라는 사실이 밝혀졌다. 17세기 말에는 빛의 성질이 논란의 대상이 되었다. 뉴턴은 빛이 수많은 작은 입자로 이루어진다고 믿었다. 반면 네덜란드의 물리학자 크리스티안 하위헌스는 빛이 파동이라는 강력한 증거를 제시했다. 논쟁을 매듭지은 것은 간섭이라는 현상이었다.
- p432. 무작위성은 다양한 형태로 나타나며 혼돈 이론은 나비 한 마리의 날갯짓이 날씨를 근본적으로 바꿀 수 있다고 말한다.
- p441. '확률이란 무엇인가?'라는 철학적인 이슈는 데이터에서 확률을 계산하는 빈도주의자와 확률을 믿음의 정도로 생각하는 베이지안 사이의 깊은 분열을 초래했다.

# 데이터를 분석해 <sup>2019</sup>
★★★★☆  
통계를 쉽게 설명하는 책. 역사를 통해 흥미를 높이고, FAQ를 통해 궁금증을 소개한다. 저자가 이후에 쓴 책이 『한달 공부 데이터 분석』이다. 여기서도 마치 소설 처럼 비유해서 재미있게 소개하는데, 저자가 이전부터 재밌는 일화를 발굴해내는 데 소질이 있었던거 같다.
- p50. 근대 통계학에 가장 영향을 많이 준 학자 세 명을 뽑으라면 칼 피어슨, 로널드 피셔, 윌리엄 고셋이라 말하겠다.
- p52. 고셋은 작은 표본도 정규분포를 따를 거라고 가정하고 자유도라는 개념을 통해 새로운 분포를 만드는데 이게 바로 t-분포다.
- p202. 연관규칙 분석은 인기에 비해 역사가 그리 길지 않다. 1993년 인도 출신의 컴퓨터공학자 라케시 아그라왈과 그의 동료들이 처음 거론하면서 주목을 받았다.

# 숫자에 약한 사람들을 위한 통계학 수업 <sup>2019, 2020</sup>
- 영국의 살인마 해럴드 시프먼의 사례로 '들어가며' 시작
- p17. 데이터 문해력 <sup>data literacy</sup>이라고 번역했는데, 통계를 해석하고 다른 사람의 통계적 결론을 이해하고 비판적으로 분석하는 능력 모두를 의미.
- p18. PPDAC 모형. Problem-Plan-Data-Analysis-Conclusion
- p51. 대중의(군중의) 지혜
- p82. 팩트풀니스 TV 논쟁: 불행히도 책이란 매체는 움직이는 시각 자료들을 보여주기에 적절치 못하다. 한 번은 로슬링이 세상에 대한 잘못된 편견을 앵무새마냥 되풀이하는 덴마크 저널리스트와 텔레비전에서 논쟁한 적이 있었다. 이때 로슬링은 "이 사실들은 논쟁거리가 아닙니다. 내가 맞고, 당신이 틀렸습니다"라는 직설적인 발언으로 화제가 됐다.
- p240. 조건부 확률:  
유방암 촬영은 90% 정확하다. 검사를 받은 여성 중 1%에게 실제 암이 있다고 가정했을때 촬영결과가 양성이 나왔을때 실제로 암에 걸릴 확률은?  
    - 1,000  
    - 정상(990), 암(10)  
    - 정상-양성(99), 정상-음성(891), 암-양성(9), 암-음성(1)  
    - 양성일때 $$\frac{9}{108}$$ 확률로 진짜 암이다. 8.3%
- p269. 신뢰구간의 원리는 1930년대 UCL에 있었던 폴란드 수학자이자 통계학자인 예르지 네이만 <sup>Jerzy Neyman</sup>과 칼 피어슨의 아들인 이건 피어슨 <sup>Egon Pearson</sup>에 의해 공식화됐다. 관례적으로 95% 신뢰구간을 가장 많이 사용하는 편이며 그 구간은 평균 $$\pm{2}$$ 표준오차에 해당한다. 미국 노동 통계국은 실업에 대하여 90% 구간을 사용하는 반면, 영국 통계청은 95% 구간을 사용한다.

# 처음 시작하는 만화 통계학 <sup>2012, 2020</sup>
아래 내용은 모두 별도 페이지로 정리 가능할 듯
- p68. 분산은 평균과의 거리를 정사각형으로 만듬. 넓이를 통해 재밌게 비유한다.
<img src="https://user-images.githubusercontent.com/1250095/102018658-df500080-3db1-11eb-8441-864401ca530e.png" width="50%">
- p79. 편찻값: 일본에서만 쓰인다고 예전에도 언급한 바 있다. 우리나라에서도 표준점수로 쓰인다. 주로 수험생들의 점수로 활용.
- p176. 대체로 정규분포를 따른다는 의미: 단봉성 <sup>single-peaked</sup> 분포, 키 등. 몸무게는 제각각이어서(특히 어른) 적합하지 않다
- p209. 정규분포 모집단에서 $$n$$개의 데이터를 추출하여 표본 <sup>sample</sup>으로 삼은 경우 t 분포를 따른다. n이 $$\infty$$면 정규분포와 같은 모양이 된다.
- p218. '모평균'의 추정을 t 분포로, '모분산' 추정은 '카이제곱분포'를 활용한다. 검정통계랑 $$\chi$$를 사용한다.

# 통계의 아름다움 <sup>2019, 2020</sup>
- p16. 우리는 이성적이며 완벽한 체계를 추구하고 최고의 경지에 도달하기를 희망한다. 그러나 경험주의와 관찰, 실험, 귀납, 계산의 힘을 무시해서는 안된다. 이는 모두 과학이기에 편파적이지 말아야 한다.

통계와 과학
- 몬티 홀 문제 같은 한 번쯤 들어봤을 유명한 여러 통계학 사건들이 총 망라되어 있다. 중국책이다 보니 중국 사례도 심심찮게 등장한다.
- p55. 조지 박스: "모든 모델은 잘못되었지만 일부는 유용하다"

데이터와 수학
- p86. 어떤 과학적 발견도 최초 발견자의 이름을 따서 명명되지 않는 '스티글러의 법칙'

데이터 시각화
- 존 스노우의 데이터 지도, 나이팅게일의 파이 차트, 미나드의 나폴레옹 원정 차트 소개
- p153. 존 투키는 20세기 후반기 가장 중요한 세 명의 통계학자 중 한 명으로 칭송 받았다. 그가 제시한 탐색적 데이터 분석(EDA)의 사상은 통계 그래프의 역할을 매우 중시하여 데이터 시각화 방면에서 많은 창의적 작업을 진행하였다. 저서에서 박스 플롯 또한 소개.

모델과 방법
- p181. 맥주와 기저귀의 전설
- p212. 아름다운 필터: CNN 소개

빅데이터 시대
- 통계를 설명하는 책에서 흥미롭게도 빅데이터와 시스템에 대해서도 소개한다.
- p254. 파이썬 이야기
- p260. 클라우드 컴퓨팅을 얘기하는데, 맵리듀스와 하둡 얘기를 한다. 이건 클라우드가 아니라 빅데이터 플랫폼인데. 클라우드라 하면 AWS 등을 얘기해야 할텐데 여기서 저자가 주제 키워드를 혼동한듯 하다.

데이터의 함정
- 『좋은 선택, 나쁜 선택』, 『틀리지 않는법』에서 처럼 잘못 판단할 수 있는 주의해야할 부분을 소개한다.

# 숫자가 만만해지는 책 <sup>2018, 2020</sup>
『새빨간 거짓말, 통계』을 주로 언급한다. 실제로 그 책에 영향을 받은 내용들이 많다. 『틀리지 않는 법』을 언급하지는 않지만 그 책 처럼 통계에 주의하라는 내용이 책 내용의 주를 이룬다. 책에서는 이외에도 '이상한 문제에 대한 정답을 진지하게 추정하는 방법'을 보여주는 『위험한 과학책』도 추천한다.

- 8장 까지는 계속 숫자, 단위 등에 혼동하지 말고 제대로 추정하라는 얘기를 한다.
- 9장 통계의 4가지 거짓말: 평균에 혼동하지 말고, 편향에 주의하라는 내용, 상관관계와 인과관계를 혼동하지 말라는, 『새빨간 거짓말, 통계』 이후 거의 대부분의 통계책들이 얘기하는 내용을 동일하게 언급한다. 다른 통계책을 꾸준히 봐왔다면 색다른 내용은 없다. 특히 통계학 교수도 아닌 만큼 통계와 관련한 특이한 주장이나 사례 또한 전혀 없다.
- 10장 그래프: 그래프의 모양에 유의하라는 내용, 11장 출처를 의심하라, 12장 복잡한 계산이 쉬워지는 간편셈: 어림계산을 활용하라.
- 13장 추정이 만만해지는 페르미 문제: 페르미 문제 <sup>Fermi Problem</sup> 또는 페르미 추정 <sup>Fermi Estimation</sup>은 어떠한 문제에 대해 기초적인 지식과 논리적 추론만으로 짧은 시간 안에 대략적인 근사치를 추정하는 방법이다. e.g. 우리나라의 전봇대는 모두 몇 개인가? [^fn-fermi]

[^fn-fermi]: <https://analyticsstory.com/38>

- 14장 당신을 지키는 법: 경고 신호를 포착하라, 출처에 주의할 것, 상식을 넓히고 간편셈을 익히자, 직관과 의심을 이용하자. 책에서 했던 주장의 요약:
    - p249. '어떤 숫자나 계산이나 결론이 미심쩍으며, 회의적인 시각으로 바라볼 만한 이유가 충분하다'는 경고 신호를 포착하라.
    - p252. 항상 정보의 출처를 확인하는 것이 좋다. 정보 제공자의 속셈이 뭘까? 그들의 동기가 뭘까? 그들은 사람들에게 뭘 믿게 하려는 걸까? 광고비를 지불한 사람은 누굴까?
    - p253. 몇 가지 정확한 팩트를 암기하고 있다면, 다른 사람들이 들이댄 팩트를 훨씬 더 잘 점검할 수 있다. 인구, 비율, 크기 등에 대한 지식이 좀 있다면, 최소한 도움은 된다.
    - 스스로에게 이렇게 질문하라. '그 숫자가 너무 크거나 너무 작지 않을까? 아니면 대충 적당할까? 이게 말이 될까? 만약 사실이라면, 시사하는 바가 뭘까?' 여러분 나름의 근삿값을 추정하라.

이 책 내용 전체가 기존에 이미 통계학 관련 책을 많이 읽어왔다면 거의 겹치는 내용이며 특별히 새로운 내용은 없다. 특히 난이도가 매우 쉬운 수준으로 맞춰져 있어 책을 많이 읽는다면 사실상 건질 내용이 전혀 없다.

# 통계학을 떠받치는 일곱기둥 이야기 <sub>2016</sub>
- Information: Its Measurement and Rate of Change  
정보 측정: 정보 측정과 변화율
    - The Trial of the Pyx 주화 표본 검정  
검정용으로 쓸 주화를 몇 개씩 골라 픽스<sup>Pyx</sup>라 부르는 상자에 넣었다.
    - Abraham de Moivre 아브라함 드 무아브르  
드 무아브르는 오늘날 이항 분포에 대한 정규 근사라 부르는 유명한 결과를 1733년에 도출하지만, 벌써 1730년에 분포의 결정적 측면이 n의 제곱근 편차와 엮여 있다는 것을 알았다. 드 무아브르는 개별 관측이나 관측 오차가 오떤 분포를 따르든 주화 표본의 무게 측정 같은 관측의 합계나 평균이 정규 분포를 따르리라는 같은 결론에 이르렀다. 증명이 철저하지 못한 데다, 1824년에는 푸아송이 오늘날 코시 분포라 부르는 예외 사례를 찾아냈다.

- Likelihood: Calibration on a Probability Scale  
가능도: 확률 척도의 보정
    - Intercomparison: Within-Sample Variation as a Standard   
상호 비교: 표본 내 변동을 표준으로  
통계적으로 비교할 때 외부 기준을 참조하거나 믿지 말고 철저히 자료 내부에 있는 변동만으로 비교해야 한다는 발상이다.

- Regression: Multivariate Analysis, Bayesian Inference, and Causal Inference  
회귀: 다변량 분석, 베이즈 추론, 인과 관계 추론

- Design: Experimental Planning and the Role of Randomization  
설계: 실험 계획과 랜덤화의 역할
    - Randomization 랜덤화

- Residual: Scientific Logic, Model Comparison, and Diagnostic Display  
잔차: 과학 논리, 모형 비교, 진단 표시

# 좋은 선택, 나쁜 선택 <sub>2019</sub>
- 데이터에 기반한 선택이 좋은 선택이다  
선택의 방법에는 경험, 개연성, 영도에 따른, 다수의 선택 등 다양한 방법이 있지만 데이터에 기반한 선택이 최선이다.
- 우리의 수치에 대한 직관은 믿을 만하지 않다  
생일이 겹치는 문제(파이썬 알고리즘 인터뷰에서도 언급), 몬티 홀 문제와 같은 대표적인 확률을 잘못 계산하는 문제가 나온다. 교양 통계 서적을 자주 봤다면 한번쯤 봤을 내용.
- 확률과 통계의 함정  
독립 사건: 9번 모두 동전 앞면이 나와도 10번째에 앞면이 나올 확률은 1/2이다. 큰 수의 법칙과 이항 분포로 동전이 몇 번이나 나올지에 대한 확률을 계산할 수 있다. 1733년에 드 무아브르는 이항 분포의 시행 횟수를 크게 하면 종 모양의 분포로 근사시킬 수 있다고 주장했다. 이 분포는 지금의 정규 분포인 종 모양을 가진다. p.65 18세기 말 프랑스의 수학자 라플라스는 전체 사건이 어떤 확률 분포를 따르든 간에 표본을 뽑은 후 그 본의 평균을 구하면, 표본의 개수 n이 적당히 크기만 하다면 이 표본의 평균이 전체 사건의 집합인 모집단의 평균값을 중심으로 하는 정규 분포를 이룬다는 중심극한정리를 발표했다. p.66 
- 데이터 수치가 말하지 않는 것  
정확도와 재현율에 대해 언급하는데, 이 보다는 표본집단 <sup>sample</sup>에 대한 확률의 함정에 대해 다룬다. 모집단 <sup>population</sup>을 대표하는 표본 추출이 편향되게 <sup>bias</sup> 추출되지 않는게 중요하다. 생존 편향의 얘기도 나온다.
- 거짓말은 아닙니다  
윤리, 데이터를 부풀려 표현하는 문제, 5% p-value의 함정, 재현 불가에 대해 얘기한다.
- 숫자로 쌓아 올린 신기루  
[화물숭배](https://ko.wikipedia.org/wiki/%ED%99%94%EB%AC%BC%EC%88%AD%EB%B0%B0%EA%B3%BC%ED%95%99) <sup>Cargo Cult</sup>  
현대 사회에서 누군가에게 주술을 믿느냐고 물으면 대부분 얼굴을 붉히며 자신을 모욕하지 말라고 항의할 것이다. 그런데 아이러니한 것은 주술을 사용하여 자기 계발을 전파하는 책에 대해서는 극찬하면서 자신의 삶을 바꾸는 지표로 삼는다는 사람을 쉽게 찾아볼 수 있다는 점이다. p.132
- 선택을 해봅시다  
'엘리베이터에서 배우자 고르기'는 『알고리즘, 인생을 계산하다』에 나온 37% 문제와 유사.
- 합리적인 선택을 위해 해야 할 일  
데이터 시각화가 중요하다고 강조.

# 누구나 파이썬 통계분석 <sub>2018, 2020</sub>
PyData에 적합한 내용이지만 파이썬 기술 보다는 통계 기본에 대한 내용이기 때문에 우선 여기에 정리한다. 이 책은 여러 통계 수치를 이렇게 하면 구할 수 있다 라고 얘기하는데 어떻게 활용하는지에 대한 설명은 없다. 단순히 정의와 파이썬 코드 약간(주피터 노트북)을 보여줄 뿐이라 통계학에 대한 사전 지식이 없다면 보기 어렵다. 일본서 답게 매우 기초적인 부분부터 차근차근 짚어준다. 확실히 노트북을 놓고 함께 따라하면서 책을 읽을때 훨씬 더 잘 읽힌다. scipy.stats에 대부분의 필요한 함수가 있다.
- 추측 통계 <sup>Inferential Statistics</sup>: 표본평균 <sup>sample mean</sup>을 여러차례 반복하여 모평균 <sup>population mean</sup>을 구할 수 있다. (표본평균의 분포에서 최빈값 <sup>mode</sup>으로 정할 수 있음) 400개의 모수에서 20개의 표본으로 실험. 모평균을 점추정 <sup>point estimation</sup> 했다. 
- 이산형 확률 변수 <sup>discrete random variable</sup>, 이산형 확률 분포 <sup>discrete probability distribution</sup>
    - 이항 분포 <sup>binomial distribution</sup>: 성공 확률이 $$p$$인 베르누이 시행을 $$n$$번 했을때 성공 횟수가 따르는 분포
    - 기하 분포 <sup>geometric distribution</sup>: 베르누이 시행에서 처음 성공할 때까지 반복한 시행 횟수가 따르는 분포
    - 포아송 분포 <sup>poisson distribution</sup>: 임의의 사건이 단위 시간당 발생하는 건수가 따르는 확률분포
- 연속형 확률 변수 <sup>continuous random variable</sup>, 연속형 확률 분포 <sup>continuous probability distribution</sup>
    - 정규분포
    - 지수분포 <sup>exponential distribution</sup>: 어떤 사건이 발생하는 간격이 따르는 분포. 포아송 분포와 관련성이 강하다.
    - 카이제곱분포 <sup>chi-square dist</sup>: 여기서 부터는 분산의 구간추정이나 독립성 검정에 사용되는 특수한 확률분포
    - t 분포: 정규분포에서 모평균의 구간추정 등에 사용
    - F 분포: 분산분석 등에 사용
- 통계적 추정: 이 장부터 본격적으로 추측통계를 하기 위해 앞서 모든 준비 과정이었음. (점추정, 구간추정 <sup>interval estimation</sup>)
- 통계적 가설검증 <sup>statistical hypothesis testing</sup>: 실제로 p-value를 이용해 가설을 검증하는 과정을 다룬다.

# 신호와 소음 <sup>2012, 2020, 2021</sup>
- p624 12월의 코펜하겐은 해가 짧고 어두웠다. 설상가상으로 맥주는 비쌌는데, 덴마크에서 술을 비롯해 거의 모든 것에 매겨지는 엄청난 세금은 세계적으로 높은 경쟁력을 자랑하는 녹색기술 인프라를 구축하는 데 들어간다. 현재 덴마크의 에너지 소비량은 1960년대 말과 거의 비슷한 수준이다. 에너지 효율이 높은 미래는 '춥고 어둡고 비쌀 것이다'라는 게 그때 내가 받은 인상이다.

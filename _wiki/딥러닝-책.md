---
layout: wiki 
title: 딥러닝 책
tags: ["Books"]
last_modified_at: 2023/07/17 16:23:42
---

- [머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로 2019, 2021](#머신-러닝-교과서-with-파이썬-사이킷런-텐서플로-2019-2021)
- [딥러닝 파이토치 교과서 2022](#딥러닝-파이토치-교과서-2022)
- [김기현의 자연어 처리 딥러닝 캠프 2019](#김기현의-자연어-처리-딥러닝-캠프-2019)
- [Mastering PyTorch 2021](#mastering-pytorch-2021)
- [머신러닝 TensorFlow.js JavaScript 2019](#머신러닝-tensorflowjs-javascript-2019)
- [딥러닝을 위한 최적화와 수치해석 2020](#딥러닝을-위한-최적화와-수치해석-2020)
- [바닥부터 배우는 강화 학습 2020](#바닥부터-배우는-강화-학습-2020)

# 기초부터 시작하는 강화학습/신경망 알고리즘 <sub>2019</sub>
★★★☆☆  
비교적 초기에 출간된 책으로 강화학습을 기초부터 잘 설명한다. 아쉬운 점은 딥러닝 챕터부터 수식이 너무 많고 부가 설명이 부족해 배경지식이 없으면 이해가 어렵다는 점이다. 딥러닝은 다른 책에서도 잘 설명하는 만큼 강화학습에만 집중했으면 더 좋은 책이 됐을 것 같다.

- 4장에서 틱택토 인간, 랜덤, 몬테카를로 플레이어를 차례대로 비교한다. Q-learning(가치점수 계산), DQN(딥러닝) 플레이어도 함께 비교하여 [성능 검증](https://github.com/wikibook/rlnn/blob/master/4%EC%9E%A5%20%EC%BD%94%EB%93%9C.ipynb) 
 
# 머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로 <sup>2019, 2021</sup>
★★★★☆  
라슈카의 책이 벌써 3판까지 나왔다. 원서가 이미 2019년에 출간된 내용이라 지금 보기엔 예전 내용이지만 라슈카가 직접 다양한 실험을 통해 증명한 내용이 책에 고스란히 담겨 있어 매우 흥미롭고 유용하다.

# 딥러닝 파이토치 교과서 <sup>2022</sup>
★★☆☆☆  
2022년에 출간된 책 답지 않게 내용이 다소 진부하다. 딥러닝과 파이토치를 내세우지만 머신러닝 기초나 DT, SVM이 등장하는 것도 제목에 어울리지 않는다. 머신러닝을 쉽게 풀이해서 설명하려는 노력이 엿보이지만 그 이상을 기대하기는 어렵다.

# 김기현의 자연어 처리 딥러닝 캠프 <sup>2019</sup>
★★★☆☆  
자연어 처리에 필요한 다양한 머신러닝 알고리즘을 설명한다. 예제도 제시하지만 수식이 지나치게 많고 자세한 설명이 부족하며 여러 이론을 한 번씩 언급하고 설명하는 백과 사전식 구성에 좀 더 가깝다.

- p68 몬테카를로 샘플링: 랜덤을 이용해 임의의 함수 적분을 근사. 예를 들어 한반도의 넓이를 근사하는 것. 
- p199 딥러닝이 잘 동작하는 이유: 딥러닝이 문제를 풀기 위해 차원 축소를 수행하는 과정은 데이터가 존재하는 고차원상에서 매니폴드를 찾는 과정이다. PCA 같은 선형적인 방식에 비해 딥러닝은 비선형적인 방식으로 차원 축소를 수행하며 그 과정에서 문제를 가장 잘 해결하기 위한 매니폴드를 자연스럽게 찾아낸다.

# Mastering PyTorch <sup>2021</sup>
★★☆☆☆  
여느 Packt 책이 항상 그렇듯 트러블슈팅이나 심화 내용보다는 인터넷에서 쉽게 볼 수 있는 튜토리얼을 정리한 느낌을 주는 책이다.

# 머신러닝 TensorFlow.js JavaScript <sub>2019</sub>
★☆☆☆☆  
국내 첫 tf.js 책이라고 하는데, 정작 tf.js에 대한 내용 보다는 머신러닝 튜토리얼에 가까운 여러 수식을 매뉴얼 처럼 나열하기만 하고, 그 아래 1~2줄의 tf.js 명령을 소개하는 정도에 그친다. 그렇다고 수식에 대한 설명이 친절한 것도 아니고, 명령을 소개하는 것 외에는 굳이 tf.js 책이라 보기도 어렵다. 책 내용도 지나치게 조악하여 어디선가 해외 레퍼런스를 참조만 한게 아닌가 하는 생각이 든다. 저자가 유료로 자바스크립트 강의도 하는거 같은데, 책 수준을 보면 저자의 개발 역량이 매우 의심된다. 요근래 읽은 최악의 책이다.

# 딥러닝을 위한 최적화와 수치해석 <sup>2020</sup>
- p166. 모든 수치최적화 알고리즘은 반복법 <sup>iterative method</sup>을 사용한다. 결국은 그래디언트 디센트(1945) 계열이다. Adam을 GD와 동일선상에서 다른 알고리즘으로 분류하는데, GD와 Gradient descent optimization algorithms로 구분하고 후자의 하위로 분류[^fn-gd]하는게 적절해 보인다.

[^fn-gd]: <https://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms>

# 바닥부터 배우는 강화 학습 <sup>2020</sup>
Nov, 2020  
- 마르코프 디시전 프로세스
- 벨만 방정식
- MDP를 알 때의 플래닝
    - 밸류 평가하기 <sup>Value Evaluation</sup>
- MDP를 모를 때 밸류 평가하기
- MDP를 모를 때 최고의 정책 찾기
- 가치 기반 에이전트
    - Deep Q Learning
- 정책 기반 에이전트